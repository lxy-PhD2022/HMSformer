Args in experiment:
Namespace(accumulation_steps=2, activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', compress_len=10, d_ff=128, d_layers=1, d_model=16, data='ETTh2', data_path='ETTh2.csv', dec_in=7, decomposition=0, des='Exp', device_ids=[0, 1, 2], devices='0,1,2', distil=True, do_predict=False, dropout=0.3, dvices='0,1,2', e_layers=3, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='type3', model='MGSformer_TST', model_id='96_96', momentum=0.8, moving_avg=25, n=2, n_heads=4, n_intra=2, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=8, pct_start=0.3, period=24, pred_len=96, random_seed=2021, revin=1, root_path='./dataset/', seq_len=96, stride=8, subtract_last=0, target='OT', test_flop=False, traffic=0, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=True, x=5)
Use GPU: cuda:0
>>>>>>>start training : 24_2_2_96_96_MGSformer_TST_ETTh2_ftM_sl96_ll18_pl96_dm20_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
module.model.backbone.W_pos_intra: 80
module.model.backbone.W_pos: 480
module.model.backbone.W_pos_coarse: 140
module.model.backbone.W_P_intra.weight: 960
module.model.backbone.W_P_intra.bias: 20
module.model.backbone.W_P.weight: 240
module.model.backbone.W_P.bias: 20
module.model.backbone.W_P_coarse.weight: 1400
module.model.backbone.W_P_coarse.bias: 20
module.model.backbone.encoder.layers.0.self_attn.W_Q.weight: 400
module.model.backbone.encoder.layers.0.self_attn.W_Q.bias: 20
module.model.backbone.encoder.layers.0.self_attn.W_K.weight: 400
module.model.backbone.encoder.layers.0.self_attn.W_K.bias: 20
module.model.backbone.encoder.layers.0.self_attn.W_V.weight: 400
module.model.backbone.encoder.layers.0.self_attn.W_V.bias: 20
module.model.backbone.encoder.layers.0.self_attn.to_out.0.weight: 400
module.model.backbone.encoder.layers.0.self_attn.to_out.0.bias: 20
module.model.backbone.encoder.layers.0.norm_attn.1.weight: 20
module.model.backbone.encoder.layers.0.norm_attn.1.bias: 20
module.model.backbone.encoder.layers.0.ff.0.weight: 2560
module.model.backbone.encoder.layers.0.ff.0.bias: 128
module.model.backbone.encoder.layers.0.ff.3.weight: 2560
module.model.backbone.encoder.layers.0.ff.3.bias: 20
module.model.backbone.encoder.layers.0.norm_ffn.1.weight: 20
module.model.backbone.encoder.layers.0.norm_ffn.1.bias: 20
module.model.backbone.encoder.layers.1.self_attn.W_Q.weight: 400
module.model.backbone.encoder.layers.1.self_attn.W_Q.bias: 20
module.model.backbone.encoder.layers.1.self_attn.W_K.weight: 400
module.model.backbone.encoder.layers.1.self_attn.W_K.bias: 20
module.model.backbone.encoder.layers.1.self_attn.W_V.weight: 400
module.model.backbone.encoder.layers.1.self_attn.W_V.bias: 20
module.model.backbone.encoder.layers.1.self_attn.to_out.0.weight: 400
module.model.backbone.encoder.layers.1.self_attn.to_out.0.bias: 20
module.model.backbone.encoder.layers.1.norm_attn.1.weight: 20
module.model.backbone.encoder.layers.1.norm_attn.1.bias: 20
module.model.backbone.encoder.layers.1.ff.0.weight: 2560
module.model.backbone.encoder.layers.1.ff.0.bias: 128
module.model.backbone.encoder.layers.1.ff.3.weight: 2560
module.model.backbone.encoder.layers.1.ff.3.bias: 20
module.model.backbone.encoder.layers.1.norm_ffn.1.weight: 20
module.model.backbone.encoder.layers.1.norm_ffn.1.bias: 20
module.model.backbone.encoder.layers.2.self_attn.W_Q.weight: 400
module.model.backbone.encoder.layers.2.self_attn.W_Q.bias: 20
module.model.backbone.encoder.layers.2.self_attn.W_K.weight: 400
module.model.backbone.encoder.layers.2.self_attn.W_K.bias: 20
module.model.backbone.encoder.layers.2.self_attn.W_V.weight: 400
module.model.backbone.encoder.layers.2.self_attn.W_V.bias: 20
module.model.backbone.encoder.layers.2.self_attn.to_out.0.weight: 400
module.model.backbone.encoder.layers.2.self_attn.to_out.0.bias: 20
module.model.backbone.encoder.layers.2.norm_attn.1.weight: 20
module.model.backbone.encoder.layers.2.norm_attn.1.bias: 20
module.model.backbone.encoder.layers.2.ff.0.weight: 2560
module.model.backbone.encoder.layers.2.ff.0.bias: 128
module.model.backbone.encoder.layers.2.ff.3.weight: 2560
module.model.backbone.encoder.layers.2.ff.3.bias: 20
module.model.backbone.encoder.layers.2.norm_ffn.1.weight: 20
module.model.backbone.encoder.layers.2.norm_ffn.1.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_intra.layers.0.norm_attn.1.weight: 20
module.model.backbone.encoder_intra.layers.0.norm_attn.1.bias: 20
module.model.backbone.encoder_intra.layers.0.ff.0.weight: 2560
module.model.backbone.encoder_intra.layers.0.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.0.ff.3.weight: 2560
module.model.backbone.encoder_intra.layers.0.ff.3.bias: 20
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.weight: 20
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.W_Q.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.W_Q.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.W_K.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.W_K.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.W_V.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.W_V.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_intra.layers.1.norm_attn.1.weight: 20
module.model.backbone.encoder_intra.layers.1.norm_attn.1.bias: 20
module.model.backbone.encoder_intra.layers.1.ff.0.weight: 2560
module.model.backbone.encoder_intra.layers.1.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.1.ff.3.weight: 2560
module.model.backbone.encoder_intra.layers.1.ff.3.bias: 20
module.model.backbone.encoder_intra.layers.1.norm_ffn.1.weight: 20
module.model.backbone.encoder_intra.layers.1.norm_ffn.1.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.W_Q.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.W_Q.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.W_K.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.W_K.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.W_V.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.W_V.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_intra.layers.2.norm_attn.1.weight: 20
module.model.backbone.encoder_intra.layers.2.norm_attn.1.bias: 20
module.model.backbone.encoder_intra.layers.2.ff.0.weight: 2560
module.model.backbone.encoder_intra.layers.2.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.2.ff.3.weight: 2560
module.model.backbone.encoder_intra.layers.2.ff.3.bias: 20
module.model.backbone.encoder_intra.layers.2.norm_ffn.1.weight: 20
module.model.backbone.encoder_intra.layers.2.norm_ffn.1.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.weight: 20
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.bias: 20
module.model.backbone.encoder_coarse.layers.0.ff.0.weight: 2560
module.model.backbone.encoder_coarse.layers.0.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.0.ff.3.weight: 2560
module.model.backbone.encoder_coarse.layers.0.ff.3.bias: 20
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.weight: 20
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.W_Q.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_Q.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.W_K.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_K.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.W_V.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_V.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_coarse.layers.1.norm_attn.1.weight: 20
module.model.backbone.encoder_coarse.layers.1.norm_attn.1.bias: 20
module.model.backbone.encoder_coarse.layers.1.ff.0.weight: 2560
module.model.backbone.encoder_coarse.layers.1.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.1.ff.3.weight: 2560
module.model.backbone.encoder_coarse.layers.1.ff.3.bias: 20
module.model.backbone.encoder_coarse.layers.1.norm_ffn.1.weight: 20
module.model.backbone.encoder_coarse.layers.1.norm_ffn.1.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.W_Q.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_Q.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.W_K.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_K.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.W_V.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_V.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_coarse.layers.2.norm_attn.1.weight: 20
module.model.backbone.encoder_coarse.layers.2.norm_attn.1.bias: 20
module.model.backbone.encoder_coarse.layers.2.ff.0.weight: 2560
module.model.backbone.encoder_coarse.layers.2.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.2.ff.3.weight: 2560
module.model.backbone.encoder_coarse.layers.2.ff.3.bias: 20
module.model.backbone.encoder_coarse.layers.2.norm_ffn.1.weight: 20
module.model.backbone.encoder_coarse.layers.2.norm_ffn.1.bias: 20
module.model.head.linear.weight: 193920
module.model.head.linear.bias: 96
module.model.compress.weight: 960
module.model.compress.bias: 10
Total trainable parameters: 261598
train 8449
val 2785
test 2785
Epoch: 1 cost time: 11.567817687988281
[2024-12-07 20:30:52] [32mIntermediate result: 0.36831832  (Index 0)[0m
Epoch: 1, Steps: 66 | Train Loss: 0.5872960 Vali Loss: 0.2780842 Test Loss: 0.3683183
Validation loss decreased (inf --> 0.278084).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 10.427129983901978
[2024-12-07 20:31:06] [32mIntermediate result: 0.31025505  (Index 1)[0m
Epoch: 2, Steps: 66 | Train Loss: 0.5105570 Vali Loss: 0.2257628 Test Loss: 0.3102551
Validation loss decreased (0.278084 --> 0.225763).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 10.433902978897095
[2024-12-07 20:31:20] [32mIntermediate result: 0.3007625  (Index 2)[0m
Epoch: 3, Steps: 66 | Train Loss: 0.4690188 Vali Loss: 0.2201796 Test Loss: 0.3007625
Validation loss decreased (0.225763 --> 0.220180).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 10.504582643508911
[2024-12-07 20:31:35] [32mIntermediate result: 0.29672396  (Index 3)[0m
Epoch: 4, Steps: 66 | Train Loss: 0.4496807 Vali Loss: 0.2181372 Test Loss: 0.2967240
Validation loss decreased (0.220180 --> 0.218137).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 10.224933385848999
[2024-12-07 20:31:49] [32mIntermediate result: 0.29481083  (Index 4)[0m
Epoch: 5, Steps: 66 | Train Loss: 0.4358650 Vali Loss: 0.2177126 Test Loss: 0.2948108
Validation loss decreased (0.218137 --> 0.217713).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 10.359055995941162
[2024-12-07 20:32:03] [32mIntermediate result: 0.2949117  (Index 5)[0m
Epoch: 6, Steps: 66 | Train Loss: 0.4241524 Vali Loss: 0.2177032 Test Loss: 0.2949117
Validation loss decreased (0.217713 --> 0.217703).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 10.72837519645691
[2024-12-07 20:32:18] [32mIntermediate result: 0.29246417  (Index 6)[0m
Epoch: 7, Steps: 66 | Train Loss: 0.4167801 Vali Loss: 0.2156335 Test Loss: 0.2924642
Validation loss decreased (0.217703 --> 0.215634).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 10.4694082736969
[2024-12-07 20:32:33] [32mIntermediate result: 0.29451913  (Index 7)[0m
Epoch: 8, Steps: 66 | Train Loss: 0.4083292 Vali Loss: 0.2174765 Test Loss: 0.2945191
EarlyStopping counter: 1 out of 8
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 10.424291610717773
[2024-12-07 20:32:47] [32mIntermediate result: 0.29208934  (Index 8)[0m
Epoch: 9, Steps: 66 | Train Loss: 0.4054864 Vali Loss: 0.2143075 Test Loss: 0.2920893
Validation loss decreased (0.215634 --> 0.214307).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 10.733829736709595
[2024-12-07 20:33:01] [32mIntermediate result: 0.2915413  (Index 9)[0m
Epoch: 10, Steps: 66 | Train Loss: 0.4016484 Vali Loss: 0.2134300 Test Loss: 0.2915413
Validation loss decreased (0.214307 --> 0.213430).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 10.221744298934937
[2024-12-07 20:33:16] [32mIntermediate result: 0.29141465  (Index 10)[0m
Epoch: 11, Steps: 66 | Train Loss: 0.3987762 Vali Loss: 0.2124292 Test Loss: 0.2914146
Validation loss decreased (0.213430 --> 0.212429).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 10.551088809967041
[2024-12-07 20:33:30] [32mIntermediate result: 0.2913343  (Index 11)[0m
Epoch: 12, Steps: 66 | Train Loss: 0.3954432 Vali Loss: 0.2121944 Test Loss: 0.2913343
Validation loss decreased (0.212429 --> 0.212194).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 10.519113063812256
[2024-12-07 20:33:45] [32mIntermediate result: 0.29210004  (Index 12)[0m
Epoch: 13, Steps: 66 | Train Loss: 0.3948084 Vali Loss: 0.2125554 Test Loss: 0.2921000
EarlyStopping counter: 1 out of 8
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 10.615644216537476
[2024-12-07 20:34:00] [32mIntermediate result: 0.2915038  (Index 13)[0m
Epoch: 14, Steps: 66 | Train Loss: 0.3931797 Vali Loss: 0.2130004 Test Loss: 0.2915038
EarlyStopping counter: 2 out of 8
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 10.638799667358398
[2024-12-07 20:34:14] [32mIntermediate result: 0.29205593  (Index 14)[0m
Epoch: 15, Steps: 66 | Train Loss: 0.3923371 Vali Loss: 0.2130677 Test Loss: 0.2920559
EarlyStopping counter: 3 out of 8
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 10.35989236831665
[2024-12-07 20:34:29] [32mIntermediate result: 0.2908476  (Index 15)[0m
Epoch: 16, Steps: 66 | Train Loss: 0.3893206 Vali Loss: 0.2118878 Test Loss: 0.2908476
Validation loss decreased (0.212194 --> 0.211888).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 10.418810606002808
[2024-12-07 20:34:43] [32mIntermediate result: 0.2918007  (Index 16)[0m
Epoch: 17, Steps: 66 | Train Loss: 0.3880547 Vali Loss: 0.2120280 Test Loss: 0.2918007
EarlyStopping counter: 1 out of 8
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 10.56944489479065
[2024-12-07 20:34:57] [32mIntermediate result: 0.29001313  (Index 17)[0m
Epoch: 18, Steps: 66 | Train Loss: 0.3885625 Vali Loss: 0.2110742 Test Loss: 0.2900131
Validation loss decreased (0.211888 --> 0.211074).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 10.69395136833191
[2024-12-07 20:35:12] [32mIntermediate result: 0.29005352  (Index 18)[0m
Epoch: 19, Steps: 66 | Train Loss: 0.3874013 Vali Loss: 0.2104615 Test Loss: 0.2900535
Validation loss decreased (0.211074 --> 0.210461).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 10.725307941436768
[2024-12-07 20:35:26] [32mIntermediate result: 0.29108697  (Index 19)[0m
Epoch: 20, Steps: 66 | Train Loss: 0.3864356 Vali Loss: 0.2122755 Test Loss: 0.2910870
EarlyStopping counter: 1 out of 8
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 10.750934839248657
[2024-12-07 20:35:41] [32mIntermediate result: 0.29013878  (Index 20)[0m
Epoch: 21, Steps: 66 | Train Loss: 0.3852748 Vali Loss: 0.2103532 Test Loss: 0.2901388
Validation loss decreased (0.210461 --> 0.210353).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 10.916880130767822
[2024-12-07 20:35:55] [32mIntermediate result: 0.29145384  (Index 21)[0m
Epoch: 22, Steps: 66 | Train Loss: 0.3848361 Vali Loss: 0.2115708 Test Loss: 0.2914538
EarlyStopping counter: 1 out of 8
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 10.850631713867188
[2024-12-07 20:36:10] [32mIntermediate result: 0.29060733  (Index 22)[0m
Epoch: 23, Steps: 66 | Train Loss: 0.3838930 Vali Loss: 0.2103212 Test Loss: 0.2906073
Validation loss decreased (0.210353 --> 0.210321).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 10.514629364013672
[2024-12-07 20:36:25] [32mIntermediate result: 0.29044908  (Index 23)[0m
Epoch: 24, Steps: 66 | Train Loss: 0.3840431 Vali Loss: 0.2106848 Test Loss: 0.2904491
EarlyStopping counter: 1 out of 8
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 10.789894580841064
[2024-12-07 20:36:40] [32mIntermediate result: 0.28986374  (Index 24)[0m
Epoch: 25, Steps: 66 | Train Loss: 0.3838269 Vali Loss: 0.2102894 Test Loss: 0.2898637
Validation loss decreased (0.210321 --> 0.210289).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 10.718384981155396
[2024-12-07 20:36:54] [32mIntermediate result: 0.28988478  (Index 25)[0m
Epoch: 26, Steps: 66 | Train Loss: 0.3832460 Vali Loss: 0.2108286 Test Loss: 0.2898848
EarlyStopping counter: 1 out of 8
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 10.313589334487915
[2024-12-07 20:37:09] [32mIntermediate result: 0.28915098  (Index 26)[0m
Epoch: 27, Steps: 66 | Train Loss: 0.3826519 Vali Loss: 0.2098638 Test Loss: 0.2891510
Validation loss decreased (0.210289 --> 0.209864).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 10.728108882904053
[2024-12-07 20:37:23] [32mIntermediate result: 0.28965265  (Index 27)[0m
Epoch: 28, Steps: 66 | Train Loss: 0.3825886 Vali Loss: 0.2101108 Test Loss: 0.2896526
EarlyStopping counter: 1 out of 8
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 10.606188774108887
[2024-12-07 20:37:38] [32mIntermediate result: 0.2901046  (Index 28)[0m
Epoch: 29, Steps: 66 | Train Loss: 0.3804578 Vali Loss: 0.2097333 Test Loss: 0.2901046
Validation loss decreased (0.209864 --> 0.209733).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 10.745845317840576
[2024-12-07 20:37:53] [32mIntermediate result: 0.29117927  (Index 29)[0m
Epoch: 30, Steps: 66 | Train Loss: 0.3821972 Vali Loss: 0.2121294 Test Loss: 0.2911793
EarlyStopping counter: 1 out of 8
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 10.889995098114014
[2024-12-07 20:38:08] [32mIntermediate result: 0.29053262  (Index 30)[0m
Epoch: 31, Steps: 66 | Train Loss: 0.3808954 Vali Loss: 0.2093931 Test Loss: 0.2905326
Validation loss decreased (0.209733 --> 0.209393).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 10.862067937850952
[2024-12-07 20:38:23] [32mIntermediate result: 0.29059786  (Index 31)[0m
Epoch: 32, Steps: 66 | Train Loss: 0.3814356 Vali Loss: 0.2107588 Test Loss: 0.2905979
EarlyStopping counter: 1 out of 8
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 11.1053626537323
[2024-12-07 20:38:39] [32mIntermediate result: 0.29075938  (Index 32)[0m
Epoch: 33, Steps: 66 | Train Loss: 0.3806768 Vali Loss: 0.2113530 Test Loss: 0.2907594
EarlyStopping counter: 2 out of 8
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 10.968948125839233
[2024-12-07 20:38:54] [32mIntermediate result: 0.2904227  (Index 33)[0m
Epoch: 34, Steps: 66 | Train Loss: 0.3819001 Vali Loss: 0.2101327 Test Loss: 0.2904227
EarlyStopping counter: 3 out of 8
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 10.87217092514038
[2024-12-07 20:39:09] [32mIntermediate result: 0.29096863  (Index 34)[0m
Epoch: 35, Steps: 66 | Train Loss: 0.3798154 Vali Loss: 0.2106143 Test Loss: 0.2909686
EarlyStopping counter: 4 out of 8
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 10.896200180053711
[2024-12-07 20:39:23] [32mIntermediate result: 0.29011118  (Index 35)[0m
Epoch: 36, Steps: 66 | Train Loss: 0.3789771 Vali Loss: 0.2111391 Test Loss: 0.2901112
EarlyStopping counter: 5 out of 8
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 10.85697889328003
[2024-12-07 20:39:38] [32mIntermediate result: 0.2913739  (Index 36)[0m
Epoch: 37, Steps: 66 | Train Loss: 0.3819510 Vali Loss: 0.2106734 Test Loss: 0.2913739
EarlyStopping counter: 6 out of 8
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 10.621149063110352
[2024-12-07 20:39:53] [32mIntermediate result: 0.28956112  (Index 37)[0m
Epoch: 38, Steps: 66 | Train Loss: 0.3805883 Vali Loss: 0.2102471 Test Loss: 0.2895611
EarlyStopping counter: 7 out of 8
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 10.824022054672241
[2024-12-07 20:40:07] [32mIntermediate result: 0.2909629  (Index 38)[0m
Epoch: 39, Steps: 66 | Train Loss: 0.3808752 Vali Loss: 0.2111619 Test Loss: 0.2909629
EarlyStopping counter: 8 out of 8
Early stopping
>>>>>>>testing : 24_2_2_96_96_MGSformer_TST_ETTh2_ftM_sl96_ll18_pl96_dm20_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.29053255915641785, mae:0.338351845741272, rse:0.43059369921684265
[2024-12-07 20:40:10] [32mFinal result: 0.29053256[0m
