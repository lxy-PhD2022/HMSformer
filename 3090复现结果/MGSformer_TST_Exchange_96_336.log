Args in experiment:
Namespace(accumulation_steps=2, activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', compress_len=1, d_ff=128, d_layers=1, d_model=16, data='custom', data_path='exchange_rate.csv', dec_in=7, decomposition=0, des='Exp', device_ids=[0, 1, 2], devices='0,1,2', distil=True, do_predict=False, dropout=0.3, dvices='0,1,2', e_layers=1, embed='timeF', embed_type=0, enc_in=8, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='type3', model='MGSformer_TST', model_id='Exchange_96_336', momentum=0.8, moving_avg=25, n=12, n_heads=1, n_intra=1, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=8, pct_start=0.3, period=7, pred_len=336, random_seed=2021, revin=1, root_path='./dataset/', seq_len=96, stride=8, subtract_last=0, target='OT', test_flop=False, traffic=0, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=True, x=5)
Use GPU: cuda:0
>>>>>>>start training : 7_1_12_Exchange_96_336_MGSformer_TST_custom_ftM_sl96_ll18_pl336_dm5_nh1_el1_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
module.model.backbone.W_pos_intra: 70
module.model.backbone.W_pos: 35
module.model.backbone.W_pos_coarse: 40
module.model.backbone.W_P_intra.weight: 490
module.model.backbone.W_P_intra.bias: 5
module.model.backbone.W_P.weight: 5
module.model.backbone.W_P.bias: 5
module.model.backbone.W_P_coarse.weight: 40
module.model.backbone.W_P_coarse.bias: 5
module.model.backbone.encoder.layers.0.self_attn.W_Q.weight: 25
module.model.backbone.encoder.layers.0.self_attn.W_Q.bias: 5
module.model.backbone.encoder.layers.0.self_attn.W_K.weight: 25
module.model.backbone.encoder.layers.0.self_attn.W_K.bias: 5
module.model.backbone.encoder.layers.0.self_attn.W_V.weight: 25
module.model.backbone.encoder.layers.0.self_attn.W_V.bias: 5
module.model.backbone.encoder.layers.0.self_attn.to_out.0.weight: 25
module.model.backbone.encoder.layers.0.self_attn.to_out.0.bias: 5
module.model.backbone.encoder.layers.0.norm_attn.1.weight: 5
module.model.backbone.encoder.layers.0.norm_attn.1.bias: 5
module.model.backbone.encoder.layers.0.ff.0.weight: 640
module.model.backbone.encoder.layers.0.ff.0.bias: 128
module.model.backbone.encoder.layers.0.ff.3.weight: 640
module.model.backbone.encoder.layers.0.ff.3.bias: 5
module.model.backbone.encoder.layers.0.norm_ffn.1.weight: 5
module.model.backbone.encoder.layers.0.norm_ffn.1.bias: 5
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.weight: 25
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.bias: 5
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.weight: 25
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.bias: 5
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.weight: 25
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.bias: 5
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.weight: 25
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.bias: 5
module.model.backbone.encoder_intra.layers.0.norm_attn.1.weight: 5
module.model.backbone.encoder_intra.layers.0.norm_attn.1.bias: 5
module.model.backbone.encoder_intra.layers.0.ff.0.weight: 640
module.model.backbone.encoder_intra.layers.0.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.0.ff.3.weight: 640
module.model.backbone.encoder_intra.layers.0.ff.3.bias: 5
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.weight: 5
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.bias: 5
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.weight: 25
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.bias: 5
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.weight: 25
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.bias: 5
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.weight: 25
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.bias: 5
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.weight: 25
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.bias: 5
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.weight: 5
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.bias: 5
module.model.backbone.encoder_coarse.layers.0.ff.0.weight: 640
module.model.backbone.encoder_coarse.layers.0.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.0.ff.3.weight: 640
module.model.backbone.encoder_coarse.layers.0.ff.3.bias: 5
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.weight: 5
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.bias: 5
module.model.head.linear.weight: 189840
module.model.head.linear.bias: 336
module.model.compress.weight: 96
module.model.compress.bias: 1
Total trainable parameters: 195627
train 4880
val 425
test 1182
Epoch: 1 cost time: 4.547391414642334
[2024-12-08 00:25:51] [32mIntermediate result: 0.38608542  (Index 0)[0m
Epoch: 1, Steps: 38 | Train Loss: 0.5130815 Vali Loss: 0.5013289 Test Loss: 0.3860854
Validation loss decreased (inf --> 0.501329).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 3.204646110534668
[2024-12-08 00:25:56] [32mIntermediate result: 0.3433752  (Index 1)[0m
Epoch: 2, Steps: 38 | Train Loss: 0.4905018 Vali Loss: 0.4431503 Test Loss: 0.3433752
Validation loss decreased (0.501329 --> 0.443150).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 3.381530523300171
[2024-12-08 00:26:01] [32mIntermediate result: 0.328593  (Index 2)[0m
Epoch: 3, Steps: 38 | Train Loss: 0.4646206 Vali Loss: 0.4297975 Test Loss: 0.3285930
Validation loss decreased (0.443150 --> 0.429798).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 3.2079598903656006
[2024-12-08 00:26:05] [32mIntermediate result: 0.32452434  (Index 3)[0m
Epoch: 4, Steps: 38 | Train Loss: 0.4549616 Vali Loss: 0.4175928 Test Loss: 0.3245243
Validation loss decreased (0.429798 --> 0.417593).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 3.2624173164367676
[2024-12-08 00:26:10] [32mIntermediate result: 0.32401505  (Index 4)[0m
Epoch: 5, Steps: 38 | Train Loss: 0.4498540 Vali Loss: 0.4170902 Test Loss: 0.3240151
Validation loss decreased (0.417593 --> 0.417090).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 3.1961584091186523
[2024-12-08 00:26:14] [32mIntermediate result: 0.3219186  (Index 5)[0m
Epoch: 6, Steps: 38 | Train Loss: 0.4465294 Vali Loss: 0.4138501 Test Loss: 0.3219186
Validation loss decreased (0.417090 --> 0.413850).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 3.069612979888916
[2024-12-08 00:26:19] [32mIntermediate result: 0.32101205  (Index 6)[0m
Epoch: 7, Steps: 38 | Train Loss: 0.4453982 Vali Loss: 0.4069028 Test Loss: 0.3210120
Validation loss decreased (0.413850 --> 0.406903).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 3.2739779949188232
[2024-12-08 00:26:24] [32mIntermediate result: 0.32061183  (Index 7)[0m
Epoch: 8, Steps: 38 | Train Loss: 0.4431117 Vali Loss: 0.4096039 Test Loss: 0.3206118
EarlyStopping counter: 1 out of 8
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 3.1050570011138916
[2024-12-08 00:26:28] [32mIntermediate result: 0.31912643  (Index 8)[0m
Epoch: 9, Steps: 38 | Train Loss: 0.4421240 Vali Loss: 0.4041733 Test Loss: 0.3191264
Validation loss decreased (0.406903 --> 0.404173).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 3.346794843673706
[2024-12-08 00:26:33] [32mIntermediate result: 0.31979588  (Index 9)[0m
Epoch: 10, Steps: 38 | Train Loss: 0.4403317 Vali Loss: 0.4130599 Test Loss: 0.3197959
EarlyStopping counter: 1 out of 8
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 3.1226963996887207
[2024-12-08 00:26:37] [32mIntermediate result: 0.31859204  (Index 10)[0m
Epoch: 11, Steps: 38 | Train Loss: 0.4401753 Vali Loss: 0.4017769 Test Loss: 0.3185920
Validation loss decreased (0.404173 --> 0.401777).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 3.146124839782715
[2024-12-08 00:26:42] [32mIntermediate result: 0.31803098  (Index 11)[0m
Epoch: 12, Steps: 38 | Train Loss: 0.4392129 Vali Loss: 0.4056185 Test Loss: 0.3180310
EarlyStopping counter: 1 out of 8
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 3.1473772525787354
[2024-12-08 00:26:46] [32mIntermediate result: 0.31875712  (Index 12)[0m
Epoch: 13, Steps: 38 | Train Loss: 0.4385487 Vali Loss: 0.3983223 Test Loss: 0.3187571
Validation loss decreased (0.401777 --> 0.398322).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 3.187462091445923
[2024-12-08 00:26:51] [32mIntermediate result: 0.3185846  (Index 13)[0m
Epoch: 14, Steps: 38 | Train Loss: 0.4377711 Vali Loss: 0.4018140 Test Loss: 0.3185846
EarlyStopping counter: 1 out of 8
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 3.539789915084839
[2024-12-08 00:26:56] [32mIntermediate result: 0.31810698  (Index 14)[0m
Epoch: 15, Steps: 38 | Train Loss: 0.4374635 Vali Loss: 0.3970122 Test Loss: 0.3181070
Validation loss decreased (0.398322 --> 0.397012).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 3.2992870807647705
[2024-12-08 00:27:00] [32mIntermediate result: 0.31853792  (Index 15)[0m
Epoch: 16, Steps: 38 | Train Loss: 0.4368866 Vali Loss: 0.4003119 Test Loss: 0.3185379
EarlyStopping counter: 1 out of 8
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 3.104278326034546
[2024-12-08 00:27:05] [32mIntermediate result: 0.3181812  (Index 16)[0m
Epoch: 17, Steps: 38 | Train Loss: 0.4370192 Vali Loss: 0.4020101 Test Loss: 0.3181812
EarlyStopping counter: 2 out of 8
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 3.3324849605560303
[2024-12-08 00:27:09] [32mIntermediate result: 0.31811082  (Index 17)[0m
Epoch: 18, Steps: 38 | Train Loss: 0.4369447 Vali Loss: 0.3989274 Test Loss: 0.3181108
EarlyStopping counter: 3 out of 8
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 3.4367802143096924
[2024-12-08 00:27:14] [32mIntermediate result: 0.3177637  (Index 18)[0m
Epoch: 19, Steps: 38 | Train Loss: 0.4366009 Vali Loss: 0.3978167 Test Loss: 0.3177637
EarlyStopping counter: 4 out of 8
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 3.375661611557007
[2024-12-08 00:27:19] [32mIntermediate result: 0.317842  (Index 19)[0m
Epoch: 20, Steps: 38 | Train Loss: 0.4358354 Vali Loss: 0.4034507 Test Loss: 0.3178420
EarlyStopping counter: 5 out of 8
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 3.0154898166656494
[2024-12-08 00:27:23] [32mIntermediate result: 0.31816787  (Index 20)[0m
Epoch: 21, Steps: 38 | Train Loss: 0.4363571 Vali Loss: 0.3956714 Test Loss: 0.3181679
Validation loss decreased (0.397012 --> 0.395671).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 3.427640438079834
[2024-12-08 00:27:28] [32mIntermediate result: 0.31809235  (Index 21)[0m
Epoch: 22, Steps: 38 | Train Loss: 0.4352291 Vali Loss: 0.4012910 Test Loss: 0.3180923
EarlyStopping counter: 1 out of 8
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 3.550900936126709
[2024-12-08 00:27:33] [32mIntermediate result: 0.31795654  (Index 22)[0m
Epoch: 23, Steps: 38 | Train Loss: 0.4361298 Vali Loss: 0.4007301 Test Loss: 0.3179565
EarlyStopping counter: 2 out of 8
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 3.2289485931396484
[2024-12-08 00:27:37] [32mIntermediate result: 0.31799093  (Index 23)[0m
Epoch: 24, Steps: 38 | Train Loss: 0.4356354 Vali Loss: 0.4036574 Test Loss: 0.3179909
EarlyStopping counter: 3 out of 8
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 3.1290903091430664
[2024-12-08 00:27:42] [32mIntermediate result: 0.31795788  (Index 24)[0m
Epoch: 25, Steps: 38 | Train Loss: 0.4353501 Vali Loss: 0.4009897 Test Loss: 0.3179579
EarlyStopping counter: 4 out of 8
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 3.446101665496826
[2024-12-08 00:27:47] [32mIntermediate result: 0.31789795  (Index 25)[0m
Epoch: 26, Steps: 38 | Train Loss: 0.4348529 Vali Loss: 0.3980483 Test Loss: 0.3178979
EarlyStopping counter: 5 out of 8
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 3.3111655712127686
[2024-12-08 00:27:51] [32mIntermediate result: 0.3180201  (Index 26)[0m
Epoch: 27, Steps: 38 | Train Loss: 0.4349216 Vali Loss: 0.4030823 Test Loss: 0.3180201
EarlyStopping counter: 6 out of 8
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 3.076112747192383
[2024-12-08 00:27:56] [32mIntermediate result: 0.31788617  (Index 27)[0m
Epoch: 28, Steps: 38 | Train Loss: 0.4346322 Vali Loss: 0.4008197 Test Loss: 0.3178862
EarlyStopping counter: 7 out of 8
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 3.0107791423797607
[2024-12-08 00:28:00] [32mIntermediate result: 0.3179426  (Index 28)[0m
Epoch: 29, Steps: 38 | Train Loss: 0.4348288 Vali Loss: 0.3979898 Test Loss: 0.3179426
EarlyStopping counter: 8 out of 8
Early stopping
>>>>>>>testing : 7_1_12_Exchange_96_336_MGSformer_TST_custom_ftM_sl96_ll18_pl336_dm5_nh1_el1_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1182
mse:0.3181679844856262, mae:0.407061904668808, rse:0.4394659399986267
[2024-12-08 00:28:01] [32mFinal result: 0.31816798[0m
