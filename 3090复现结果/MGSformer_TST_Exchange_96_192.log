Args in experiment:
Namespace(accumulation_steps=2, activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', compress_len=3, d_ff=128, d_layers=1, d_model=16, data='custom', data_path='exchange_rate.csv', dec_in=7, decomposition=0, des='Exp', device_ids=[0, 1, 2], devices='0,1,2', distil=True, do_predict=False, dropout=0.3, dvices='0,1,2', e_layers=1, embed='timeF', embed_type=0, enc_in=8, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='type3', model='MGSformer_TST', model_id='Exchange_96_192', momentum=0.8, moving_avg=25, n=10, n_heads=1, n_intra=4, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=8, pct_start=0.3, period=6, pred_len=192, random_seed=2021, revin=1, root_path='./dataset/', seq_len=96, stride=8, subtract_last=0, target='OT', test_flop=False, traffic=0, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=True, x=5)
Use GPU: cuda:0
>>>>>>>start training : 6_4_10_Exchange_96_192_MGSformer_TST_custom_ftM_sl96_ll18_pl192_dm5_nh1_el1_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
module.model.backbone.W_pos_intra: 80
module.model.backbone.W_pos: 30
module.model.backbone.W_pos_coarse: 40
module.model.backbone.W_P_intra.weight: 120
module.model.backbone.W_P_intra.bias: 5
module.model.backbone.W_P.weight: 5
module.model.backbone.W_P.bias: 5
module.model.backbone.W_P_coarse.weight: 120
module.model.backbone.W_P_coarse.bias: 5
module.model.backbone.encoder.layers.0.self_attn.W_Q.weight: 25
module.model.backbone.encoder.layers.0.self_attn.W_Q.bias: 5
module.model.backbone.encoder.layers.0.self_attn.W_K.weight: 25
module.model.backbone.encoder.layers.0.self_attn.W_K.bias: 5
module.model.backbone.encoder.layers.0.self_attn.W_V.weight: 25
module.model.backbone.encoder.layers.0.self_attn.W_V.bias: 5
module.model.backbone.encoder.layers.0.self_attn.to_out.0.weight: 25
module.model.backbone.encoder.layers.0.self_attn.to_out.0.bias: 5
module.model.backbone.encoder.layers.0.norm_attn.1.weight: 5
module.model.backbone.encoder.layers.0.norm_attn.1.bias: 5
module.model.backbone.encoder.layers.0.ff.0.weight: 640
module.model.backbone.encoder.layers.0.ff.0.bias: 128
module.model.backbone.encoder.layers.0.ff.3.weight: 640
module.model.backbone.encoder.layers.0.ff.3.bias: 5
module.model.backbone.encoder.layers.0.norm_ffn.1.weight: 5
module.model.backbone.encoder.layers.0.norm_ffn.1.bias: 5
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.weight: 25
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.bias: 5
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.weight: 25
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.bias: 5
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.weight: 25
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.bias: 5
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.weight: 25
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.bias: 5
module.model.backbone.encoder_intra.layers.0.norm_attn.1.weight: 5
module.model.backbone.encoder_intra.layers.0.norm_attn.1.bias: 5
module.model.backbone.encoder_intra.layers.0.ff.0.weight: 640
module.model.backbone.encoder_intra.layers.0.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.0.ff.3.weight: 640
module.model.backbone.encoder_intra.layers.0.ff.3.bias: 5
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.weight: 5
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.bias: 5
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.weight: 25
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.bias: 5
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.weight: 25
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.bias: 5
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.weight: 25
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.bias: 5
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.weight: 25
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.bias: 5
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.weight: 5
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.bias: 5
module.model.backbone.encoder_coarse.layers.0.ff.0.weight: 640
module.model.backbone.encoder_coarse.layers.0.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.0.ff.3.weight: 640
module.model.backbone.encoder_coarse.layers.0.ff.3.bias: 5
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.weight: 5
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.bias: 5
module.model.head.linear.weight: 108480
module.model.head.linear.bias: 192
module.model.compress.weight: 288
module.model.compress.bias: 3
Total trainable parameters: 114032
train 5024
val 569
test 1326
Epoch: 1 cost time: 4.534074068069458
[2024-12-08 00:24:03] [32mIntermediate result: 0.23859067  (Index 0)[0m
Epoch: 1, Steps: 39 | Train Loss: 0.3429347 Vali Loss: 0.3088278 Test Loss: 0.2385907
Validation loss decreased (inf --> 0.308828).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 3.0958549976348877
[2024-12-08 00:24:07] [32mIntermediate result: 0.19653694  (Index 1)[0m
Epoch: 2, Steps: 39 | Train Loss: 0.3139156 Vali Loss: 0.2634022 Test Loss: 0.1965369
Validation loss decreased (0.308828 --> 0.263402).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 2.9653749465942383
[2024-12-08 00:24:11] [32mIntermediate result: 0.18314555  (Index 2)[0m
Epoch: 3, Steps: 39 | Train Loss: 0.2857701 Vali Loss: 0.2567794 Test Loss: 0.1831456
Validation loss decreased (0.263402 --> 0.256779).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 2.8938472270965576
[2024-12-08 00:24:16] [32mIntermediate result: 0.17899477  (Index 3)[0m
Epoch: 4, Steps: 39 | Train Loss: 0.2762666 Vali Loss: 0.2498441 Test Loss: 0.1789948
Validation loss decreased (0.256779 --> 0.249844).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 2.8761916160583496
[2024-12-08 00:24:20] [32mIntermediate result: 0.17676134  (Index 4)[0m
Epoch: 5, Steps: 39 | Train Loss: 0.2714086 Vali Loss: 0.2450316 Test Loss: 0.1767613
Validation loss decreased (0.249844 --> 0.245032).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 3.025709867477417
[2024-12-08 00:24:24] [32mIntermediate result: 0.1748918  (Index 5)[0m
Epoch: 6, Steps: 39 | Train Loss: 0.2686233 Vali Loss: 0.2437817 Test Loss: 0.1748918
Validation loss decreased (0.245032 --> 0.243782).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 3.452700138092041
[2024-12-08 00:24:29] [32mIntermediate result: 0.17424546  (Index 6)[0m
Epoch: 7, Steps: 39 | Train Loss: 0.2659531 Vali Loss: 0.2411300 Test Loss: 0.1742455
Validation loss decreased (0.243782 --> 0.241130).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 3.1352813243865967
[2024-12-08 00:24:33] [32mIntermediate result: 0.17313516  (Index 7)[0m
Epoch: 8, Steps: 39 | Train Loss: 0.2646557 Vali Loss: 0.2418130 Test Loss: 0.1731352
EarlyStopping counter: 1 out of 8
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 3.094721794128418
[2024-12-08 00:24:38] [32mIntermediate result: 0.17235452  (Index 8)[0m
Epoch: 9, Steps: 39 | Train Loss: 0.2633209 Vali Loss: 0.2367268 Test Loss: 0.1723545
Validation loss decreased (0.241130 --> 0.236727).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 3.1629607677459717
[2024-12-08 00:24:42] [32mIntermediate result: 0.17232743  (Index 9)[0m
Epoch: 10, Steps: 39 | Train Loss: 0.2618357 Vali Loss: 0.2369862 Test Loss: 0.1723274
EarlyStopping counter: 1 out of 8
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 2.9916484355926514
[2024-12-08 00:24:47] [32mIntermediate result: 0.17181736  (Index 10)[0m
Epoch: 11, Steps: 39 | Train Loss: 0.2618714 Vali Loss: 0.2371059 Test Loss: 0.1718174
EarlyStopping counter: 2 out of 8
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 3.4665982723236084
[2024-12-08 00:24:52] [32mIntermediate result: 0.17154114  (Index 11)[0m
Epoch: 12, Steps: 39 | Train Loss: 0.2607479 Vali Loss: 0.2366179 Test Loss: 0.1715411
Validation loss decreased (0.236727 --> 0.236618).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 3.101275682449341
[2024-12-08 00:24:56] [32mIntermediate result: 0.17141327  (Index 12)[0m
Epoch: 13, Steps: 39 | Train Loss: 0.2599797 Vali Loss: 0.2349818 Test Loss: 0.1714133
Validation loss decreased (0.236618 --> 0.234982).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 3.224351406097412
[2024-12-08 00:25:01] [32mIntermediate result: 0.17119323  (Index 13)[0m
Epoch: 14, Steps: 39 | Train Loss: 0.2597384 Vali Loss: 0.2324720 Test Loss: 0.1711932
Validation loss decreased (0.234982 --> 0.232472).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 3.2894721031188965
[2024-12-08 00:25:05] [32mIntermediate result: 0.17078239  (Index 14)[0m
Epoch: 15, Steps: 39 | Train Loss: 0.2594896 Vali Loss: 0.2310089 Test Loss: 0.1707824
Validation loss decreased (0.232472 --> 0.231009).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 2.9172818660736084
[2024-12-08 00:25:09] [32mIntermediate result: 0.17069106  (Index 15)[0m
Epoch: 16, Steps: 39 | Train Loss: 0.2588013 Vali Loss: 0.2349559 Test Loss: 0.1706911
EarlyStopping counter: 1 out of 8
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 2.9913575649261475
[2024-12-08 00:25:14] [32mIntermediate result: 0.17083164  (Index 16)[0m
Epoch: 17, Steps: 39 | Train Loss: 0.2579392 Vali Loss: 0.2341741 Test Loss: 0.1708316
EarlyStopping counter: 2 out of 8
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 3.062884569168091
[2024-12-08 00:25:18] [32mIntermediate result: 0.1706099  (Index 17)[0m
Epoch: 18, Steps: 39 | Train Loss: 0.2584238 Vali Loss: 0.2358498 Test Loss: 0.1706099
EarlyStopping counter: 3 out of 8
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 2.9866783618927
[2024-12-08 00:25:23] [32mIntermediate result: 0.1706066  (Index 18)[0m
Epoch: 19, Steps: 39 | Train Loss: 0.2579980 Vali Loss: 0.2338967 Test Loss: 0.1706066
EarlyStopping counter: 4 out of 8
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 3.123645305633545
[2024-12-08 00:25:27] [32mIntermediate result: 0.17056043  (Index 19)[0m
Epoch: 20, Steps: 39 | Train Loss: 0.2578250 Vali Loss: 0.2326100 Test Loss: 0.1705604
EarlyStopping counter: 5 out of 8
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 3.2390832901000977
[2024-12-08 00:25:32] [32mIntermediate result: 0.17025891  (Index 20)[0m
Epoch: 21, Steps: 39 | Train Loss: 0.2576573 Vali Loss: 0.2323617 Test Loss: 0.1702589
EarlyStopping counter: 6 out of 8
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 2.983110189437866
[2024-12-08 00:25:36] [32mIntermediate result: 0.17020555  (Index 21)[0m
Epoch: 22, Steps: 39 | Train Loss: 0.2574617 Vali Loss: 0.2336683 Test Loss: 0.1702055
EarlyStopping counter: 7 out of 8
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 2.801589012145996
[2024-12-08 00:25:40] [32mIntermediate result: 0.17026934  (Index 22)[0m
Epoch: 23, Steps: 39 | Train Loss: 0.2572182 Vali Loss: 0.2334797 Test Loss: 0.1702693
EarlyStopping counter: 8 out of 8
Early stopping
>>>>>>>testing : 6_4_10_Exchange_96_192_MGSformer_TST_custom_ftM_sl96_ll18_pl192_dm5_nh1_el1_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1326
mse:0.17078237235546112, mae:0.29423198103904724, rse:0.3196052014827728
[2024-12-08 00:25:41] [32mFinal result: 0.17078237[0m
