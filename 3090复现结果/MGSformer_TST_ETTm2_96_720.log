Args in experiment:
Namespace(accumulation_steps=2, activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', compress_len=10, d_ff=256, d_layers=1, d_model=128, data='ETTm2', data_path='ETTm2.csv', dec_in=7, decomposition=0, des='Exp', device_ids=[0, 1, 2], devices='0,1,2', distil=True, do_predict=False, dropout=0.2, dvices='0,1,2', e_layers=3, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.2, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='TST', model='MGSformer_TST', model_id='96_720', momentum=0.8, moving_avg=25, n=2, n_heads=16, n_intra=2, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=8, pct_start=0.4, period=24, pred_len=720, random_seed=2021, revin=1, root_path='./dataset/', seq_len=96, stride=8, subtract_last=0, target='OT', test_flop=False, traffic=0, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=True, x=5)
Use GPU: cuda:0
>>>>>>>start training : 24_2_2_96_720_MGSformer_TST_ETTm2_ftM_sl96_ll18_pl720_dm80_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
module.model.backbone.W_pos_intra: 320
module.model.backbone.W_pos: 1920
module.model.backbone.W_pos_coarse: 560
module.model.backbone.W_P_intra.weight: 3840
module.model.backbone.W_P_intra.bias: 80
module.model.backbone.W_P.weight: 960
module.model.backbone.W_P.bias: 80
module.model.backbone.W_P_coarse.weight: 5600
module.model.backbone.W_P_coarse.bias: 80
module.model.backbone.encoder.layers.0.self_attn.W_Q.weight: 6400
module.model.backbone.encoder.layers.0.self_attn.W_Q.bias: 80
module.model.backbone.encoder.layers.0.self_attn.W_K.weight: 6400
module.model.backbone.encoder.layers.0.self_attn.W_K.bias: 80
module.model.backbone.encoder.layers.0.self_attn.W_V.weight: 6400
module.model.backbone.encoder.layers.0.self_attn.W_V.bias: 80
module.model.backbone.encoder.layers.0.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder.layers.0.self_attn.to_out.0.bias: 80
module.model.backbone.encoder.layers.0.norm_attn.1.weight: 80
module.model.backbone.encoder.layers.0.norm_attn.1.bias: 80
module.model.backbone.encoder.layers.0.ff.0.weight: 20480
module.model.backbone.encoder.layers.0.ff.0.bias: 256
module.model.backbone.encoder.layers.0.ff.3.weight: 20480
module.model.backbone.encoder.layers.0.ff.3.bias: 80
module.model.backbone.encoder.layers.0.norm_ffn.1.weight: 80
module.model.backbone.encoder.layers.0.norm_ffn.1.bias: 80
module.model.backbone.encoder.layers.1.self_attn.W_Q.weight: 6400
module.model.backbone.encoder.layers.1.self_attn.W_Q.bias: 80
module.model.backbone.encoder.layers.1.self_attn.W_K.weight: 6400
module.model.backbone.encoder.layers.1.self_attn.W_K.bias: 80
module.model.backbone.encoder.layers.1.self_attn.W_V.weight: 6400
module.model.backbone.encoder.layers.1.self_attn.W_V.bias: 80
module.model.backbone.encoder.layers.1.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder.layers.1.self_attn.to_out.0.bias: 80
module.model.backbone.encoder.layers.1.norm_attn.1.weight: 80
module.model.backbone.encoder.layers.1.norm_attn.1.bias: 80
module.model.backbone.encoder.layers.1.ff.0.weight: 20480
module.model.backbone.encoder.layers.1.ff.0.bias: 256
module.model.backbone.encoder.layers.1.ff.3.weight: 20480
module.model.backbone.encoder.layers.1.ff.3.bias: 80
module.model.backbone.encoder.layers.1.norm_ffn.1.weight: 80
module.model.backbone.encoder.layers.1.norm_ffn.1.bias: 80
module.model.backbone.encoder.layers.2.self_attn.W_Q.weight: 6400
module.model.backbone.encoder.layers.2.self_attn.W_Q.bias: 80
module.model.backbone.encoder.layers.2.self_attn.W_K.weight: 6400
module.model.backbone.encoder.layers.2.self_attn.W_K.bias: 80
module.model.backbone.encoder.layers.2.self_attn.W_V.weight: 6400
module.model.backbone.encoder.layers.2.self_attn.W_V.bias: 80
module.model.backbone.encoder.layers.2.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder.layers.2.self_attn.to_out.0.bias: 80
module.model.backbone.encoder.layers.2.norm_attn.1.weight: 80
module.model.backbone.encoder.layers.2.norm_attn.1.bias: 80
module.model.backbone.encoder.layers.2.ff.0.weight: 20480
module.model.backbone.encoder.layers.2.ff.0.bias: 256
module.model.backbone.encoder.layers.2.ff.3.weight: 20480
module.model.backbone.encoder.layers.2.ff.3.bias: 80
module.model.backbone.encoder.layers.2.norm_ffn.1.weight: 80
module.model.backbone.encoder.layers.2.norm_ffn.1.bias: 80
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.weight: 6400
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.bias: 80
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.weight: 6400
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.bias: 80
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.weight: 6400
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.bias: 80
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.bias: 80
module.model.backbone.encoder_intra.layers.0.norm_attn.1.weight: 80
module.model.backbone.encoder_intra.layers.0.norm_attn.1.bias: 80
module.model.backbone.encoder_intra.layers.0.ff.0.weight: 20480
module.model.backbone.encoder_intra.layers.0.ff.0.bias: 256
module.model.backbone.encoder_intra.layers.0.ff.3.weight: 20480
module.model.backbone.encoder_intra.layers.0.ff.3.bias: 80
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.weight: 80
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.bias: 80
module.model.backbone.encoder_intra.layers.1.self_attn.W_Q.weight: 6400
module.model.backbone.encoder_intra.layers.1.self_attn.W_Q.bias: 80
module.model.backbone.encoder_intra.layers.1.self_attn.W_K.weight: 6400
module.model.backbone.encoder_intra.layers.1.self_attn.W_K.bias: 80
module.model.backbone.encoder_intra.layers.1.self_attn.W_V.weight: 6400
module.model.backbone.encoder_intra.layers.1.self_attn.W_V.bias: 80
module.model.backbone.encoder_intra.layers.1.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder_intra.layers.1.self_attn.to_out.0.bias: 80
module.model.backbone.encoder_intra.layers.1.norm_attn.1.weight: 80
module.model.backbone.encoder_intra.layers.1.norm_attn.1.bias: 80
module.model.backbone.encoder_intra.layers.1.ff.0.weight: 20480
module.model.backbone.encoder_intra.layers.1.ff.0.bias: 256
module.model.backbone.encoder_intra.layers.1.ff.3.weight: 20480
module.model.backbone.encoder_intra.layers.1.ff.3.bias: 80
module.model.backbone.encoder_intra.layers.1.norm_ffn.1.weight: 80
module.model.backbone.encoder_intra.layers.1.norm_ffn.1.bias: 80
module.model.backbone.encoder_intra.layers.2.self_attn.W_Q.weight: 6400
module.model.backbone.encoder_intra.layers.2.self_attn.W_Q.bias: 80
module.model.backbone.encoder_intra.layers.2.self_attn.W_K.weight: 6400
module.model.backbone.encoder_intra.layers.2.self_attn.W_K.bias: 80
module.model.backbone.encoder_intra.layers.2.self_attn.W_V.weight: 6400
module.model.backbone.encoder_intra.layers.2.self_attn.W_V.bias: 80
module.model.backbone.encoder_intra.layers.2.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder_intra.layers.2.self_attn.to_out.0.bias: 80
module.model.backbone.encoder_intra.layers.2.norm_attn.1.weight: 80
module.model.backbone.encoder_intra.layers.2.norm_attn.1.bias: 80
module.model.backbone.encoder_intra.layers.2.ff.0.weight: 20480
module.model.backbone.encoder_intra.layers.2.ff.0.bias: 256
module.model.backbone.encoder_intra.layers.2.ff.3.weight: 20480
module.model.backbone.encoder_intra.layers.2.ff.3.bias: 80
module.model.backbone.encoder_intra.layers.2.norm_ffn.1.weight: 80
module.model.backbone.encoder_intra.layers.2.norm_ffn.1.bias: 80
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.weight: 6400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.bias: 80
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.weight: 6400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.bias: 80
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.weight: 6400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.bias: 80
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.bias: 80
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.weight: 80
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.bias: 80
module.model.backbone.encoder_coarse.layers.0.ff.0.weight: 20480
module.model.backbone.encoder_coarse.layers.0.ff.0.bias: 256
module.model.backbone.encoder_coarse.layers.0.ff.3.weight: 20480
module.model.backbone.encoder_coarse.layers.0.ff.3.bias: 80
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.weight: 80
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.bias: 80
module.model.backbone.encoder_coarse.layers.1.self_attn.W_Q.weight: 6400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_Q.bias: 80
module.model.backbone.encoder_coarse.layers.1.self_attn.W_K.weight: 6400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_K.bias: 80
module.model.backbone.encoder_coarse.layers.1.self_attn.W_V.weight: 6400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_V.bias: 80
module.model.backbone.encoder_coarse.layers.1.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder_coarse.layers.1.self_attn.to_out.0.bias: 80
module.model.backbone.encoder_coarse.layers.1.norm_attn.1.weight: 80
module.model.backbone.encoder_coarse.layers.1.norm_attn.1.bias: 80
module.model.backbone.encoder_coarse.layers.1.ff.0.weight: 20480
module.model.backbone.encoder_coarse.layers.1.ff.0.bias: 256
module.model.backbone.encoder_coarse.layers.1.ff.3.weight: 20480
module.model.backbone.encoder_coarse.layers.1.ff.3.bias: 80
module.model.backbone.encoder_coarse.layers.1.norm_ffn.1.weight: 80
module.model.backbone.encoder_coarse.layers.1.norm_ffn.1.bias: 80
module.model.backbone.encoder_coarse.layers.2.self_attn.W_Q.weight: 6400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_Q.bias: 80
module.model.backbone.encoder_coarse.layers.2.self_attn.W_K.weight: 6400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_K.bias: 80
module.model.backbone.encoder_coarse.layers.2.self_attn.W_V.weight: 6400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_V.bias: 80
module.model.backbone.encoder_coarse.layers.2.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder_coarse.layers.2.self_attn.to_out.0.bias: 80
module.model.backbone.encoder_coarse.layers.2.norm_attn.1.weight: 80
module.model.backbone.encoder_coarse.layers.2.norm_attn.1.bias: 80
module.model.backbone.encoder_coarse.layers.2.ff.0.weight: 20480
module.model.backbone.encoder_coarse.layers.2.ff.0.bias: 256
module.model.backbone.encoder_coarse.layers.2.ff.3.weight: 20480
module.model.backbone.encoder_coarse.layers.2.ff.3.bias: 80
module.model.backbone.encoder_coarse.layers.2.norm_ffn.1.weight: 80
module.model.backbone.encoder_coarse.layers.2.norm_ffn.1.bias: 80
module.model.head.linear.weight: 5817600
module.model.head.linear.bias: 720
module.model.compress.weight: 960
module.model.compress.bias: 10
Total trainable parameters: 6440554
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.7435111
	speed: 0.1686s/iter; left time: 4417.3916s
	iters: 200, epoch: 1 | loss: 0.8202976
	speed: 0.1475s/iter; left time: 3850.6345s
Epoch: 1 cost time: 40.46205544471741
[2024-12-07 23:50:04] [32mIntermediate result: 0.41537526  (Index 0)[0m
Epoch: 1, Steps: 263 | Train Loss: 0.6242066 Vali Loss: 0.2975133 Test Loss: 0.4153753
Validation loss decreased (inf --> 0.297513).  Saving model ...
Updating learning rate to 4.1479961011495344e-06
	iters: 100, epoch: 2 | loss: 0.6194047
	speed: 0.3805s/iter; left time: 9868.7953s
	iters: 200, epoch: 2 | loss: 0.6887256
	speed: 0.1511s/iter; left time: 3904.8744s
Epoch: 2 cost time: 39.99929404258728
[2024-12-07 23:50:57] [32mIntermediate result: 0.41066375  (Index 1)[0m
Epoch: 2, Steps: 263 | Train Loss: 0.6071006 Vali Loss: 0.2941857 Test Loss: 0.4106638
Validation loss decreased (0.297513 --> 0.294186).  Saving model ...
Updating learning rate to 4.591071786016676e-06
	iters: 100, epoch: 3 | loss: 0.6404496
	speed: 0.3789s/iter; left time: 9728.1652s
	iters: 200, epoch: 3 | loss: 0.5959835
	speed: 0.1521s/iter; left time: 3889.3671s
Epoch: 3 cost time: 39.94585132598877
[2024-12-07 23:51:49] [32mIntermediate result: 0.4080875  (Index 2)[0m
Epoch: 3, Steps: 263 | Train Loss: 0.6008780 Vali Loss: 0.2921328 Test Loss: 0.4080875
Validation loss decreased (0.294186 --> 0.292133).  Saving model ...
Updating learning rate to 5.326494826523285e-06
	iters: 100, epoch: 4 | loss: 0.3747977
	speed: 0.3724s/iter; left time: 9464.5208s
	iters: 200, epoch: 4 | loss: 0.5786349
	speed: 0.1521s/iter; left time: 3849.8089s
Epoch: 4 cost time: 39.853999376297
[2024-12-07 23:52:43] [32mIntermediate result: 0.4059868  (Index 3)[0m
Epoch: 4, Steps: 263 | Train Loss: 0.5956339 Vali Loss: 0.2916671 Test Loss: 0.4059868
Validation loss decreased (0.292133 --> 0.291667).  Saving model ...
Updating learning rate to 6.349730233390618e-06
	iters: 100, epoch: 5 | loss: 0.4767632
	speed: 0.3862s/iter; left time: 9712.6591s
	iters: 200, epoch: 5 | loss: 0.4515018
	speed: 0.1499s/iter; left time: 3754.6740s
Epoch: 5 cost time: 40.13732075691223
[2024-12-07 23:53:36] [32mIntermediate result: 0.40388697  (Index 4)[0m
Epoch: 5, Steps: 263 | Train Loss: 0.5905950 Vali Loss: 0.2903768 Test Loss: 0.4038870
Validation loss decreased (0.291667 --> 0.290377).  Saving model ...
Updating learning rate to 7.654468221169727e-06
	iters: 100, epoch: 6 | loss: 1.0509655
	speed: 0.3827s/iter; left time: 9523.8816s
	iters: 200, epoch: 6 | loss: 0.5647342
	speed: 0.1475s/iter; left time: 3656.8969s
Epoch: 6 cost time: 39.904167890548706
[2024-12-07 23:54:29] [32mIntermediate result: 0.40151343  (Index 5)[0m
Epoch: 6, Steps: 263 | Train Loss: 0.5844036 Vali Loss: 0.2903763 Test Loss: 0.4015134
Validation loss decreased (0.290377 --> 0.290376).  Saving model ...
Updating learning rate to 9.232663117560071e-06
	iters: 100, epoch: 7 | loss: 0.4570844
	speed: 0.3742s/iter; left time: 9213.2697s
	iters: 200, epoch: 7 | loss: 0.5273145
	speed: 0.1467s/iter; left time: 3598.5368s
Epoch: 7 cost time: 38.84707474708557
[2024-12-07 23:55:21] [32mIntermediate result: 0.39899895  (Index 6)[0m
Epoch: 7, Steps: 263 | Train Loss: 0.5777773 Vali Loss: 0.2889733 Test Loss: 0.3989989
Validation loss decreased (0.290376 --> 0.288973).  Saving model ...
Updating learning rate to 1.1074582977081671e-05
	iters: 100, epoch: 8 | loss: 0.5313157
	speed: 0.3764s/iter; left time: 9170.2025s
	iters: 200, epoch: 8 | loss: 0.6381420
	speed: 0.1466s/iter; left time: 3557.5045s
Epoch: 8 cost time: 38.81495666503906
[2024-12-07 23:56:13] [32mIntermediate result: 0.39998013  (Index 7)[0m
Epoch: 8, Steps: 263 | Train Loss: 0.5703071 Vali Loss: 0.2898415 Test Loss: 0.3999801
EarlyStopping counter: 1 out of 8
Updating learning rate to 1.3168869593157878e-05
	iters: 100, epoch: 9 | loss: 0.4065178
	speed: 0.3825s/iter; left time: 9216.4831s
	iters: 200, epoch: 9 | loss: 0.6539792
	speed: 0.1490s/iter; left time: 3575.1452s
Epoch: 9 cost time: 39.99964261054993
[2024-12-07 23:57:07] [32mIntermediate result: 0.3964193  (Index 8)[0m
Epoch: 9, Steps: 263 | Train Loss: 0.5642357 Vali Loss: 0.2873428 Test Loss: 0.3964193
Validation loss decreased (0.288973 --> 0.287343).  Saving model ...
Updating learning rate to 1.550260853854417e-05
	iters: 100, epoch: 10 | loss: 0.6014507
	speed: 0.3889s/iter; left time: 9269.8550s
	iters: 200, epoch: 10 | loss: 0.3988292
	speed: 0.1483s/iter; left time: 3520.3714s
Epoch: 10 cost time: 39.7611198425293
[2024-12-07 23:58:00] [32mIntermediate result: 0.3957628  (Index 9)[0m
Epoch: 10, Steps: 263 | Train Loss: 0.5593920 Vali Loss: 0.2867132 Test Loss: 0.3957628
Validation loss decreased (0.287343 --> 0.286713).  Saving model ...
Updating learning rate to 1.806140880219811e-05
	iters: 100, epoch: 11 | loss: 0.4681766
	speed: 0.3734s/iter; left time: 8800.7363s
	iters: 200, epoch: 11 | loss: 0.4237212
	speed: 0.1436s/iter; left time: 3370.9336s
Epoch: 11 cost time: 38.39593052864075
[2024-12-07 23:58:52] [32mIntermediate result: 0.3966432  (Index 10)[0m
Epoch: 11, Steps: 263 | Train Loss: 0.5512754 Vali Loss: 0.2877358 Test Loss: 0.3966432
EarlyStopping counter: 1 out of 8
Updating learning rate to 2.0829491531509654e-05
	iters: 100, epoch: 12 | loss: 0.5190439
	speed: 0.3725s/iter; left time: 8683.1122s
	iters: 200, epoch: 12 | loss: 0.6190268
	speed: 0.1476s/iter; left time: 3425.0051s
Epoch: 12 cost time: 39.178783655166626
[2024-12-07 23:59:44] [32mIntermediate result: 0.39322707  (Index 11)[0m
Epoch: 12, Steps: 263 | Train Loss: 0.5437489 Vali Loss: 0.2860162 Test Loss: 0.3932271
Validation loss decreased (0.286713 --> 0.286016).  Saving model ...
Updating learning rate to 2.3789787332662254e-05
	iters: 100, epoch: 13 | loss: 0.7425333
	speed: 0.3743s/iter; left time: 8625.2740s
	iters: 200, epoch: 13 | loss: 0.5057694
	speed: 0.1469s/iter; left time: 3369.7834s
Epoch: 13 cost time: 39.19157338142395
[2024-12-08 00:00:36] [32mIntermediate result: 0.39244288  (Index 12)[0m
Epoch: 13, Steps: 263 | Train Loss: 0.5363533 Vali Loss: 0.2853402 Test Loss: 0.3924429
Validation loss decreased (0.286016 --> 0.285340).  Saving model ...
Updating learning rate to 2.6924041529121737e-05
	iters: 100, epoch: 14 | loss: 0.6883550
	speed: 0.3730s/iter; left time: 8497.0358s
	iters: 200, epoch: 14 | loss: 0.5684266
	speed: 0.1472s/iter; left time: 3338.9974s
Epoch: 14 cost time: 38.95416307449341
[2024-12-08 00:01:28] [32mIntermediate result: 0.39551854  (Index 13)[0m
Epoch: 14, Steps: 263 | Train Loss: 0.5301789 Vali Loss: 0.2886974 Test Loss: 0.3955185
EarlyStopping counter: 1 out of 8
Updating learning rate to 3.0212926729176134e-05
	iters: 100, epoch: 15 | loss: 0.4929165
	speed: 0.3705s/iter; left time: 8342.5763s
	iters: 200, epoch: 15 | loss: 0.4475748
	speed: 0.1466s/iter; left time: 3287.6330s
Epoch: 15 cost time: 38.89619207382202
[2024-12-08 00:02:20] [32mIntermediate result: 0.3954819  (Index 14)[0m
Epoch: 15, Steps: 263 | Train Loss: 0.5247841 Vali Loss: 0.2879997 Test Loss: 0.3954819
EarlyStopping counter: 2 out of 8
Updating learning rate to 3.363616200837807e-05
	iters: 100, epoch: 16 | loss: 0.3776357
	speed: 0.3742s/iter; left time: 8329.3059s
	iters: 200, epoch: 16 | loss: 0.4830561
	speed: 0.1469s/iter; left time: 3253.7032s
Epoch: 16 cost time: 39.11462092399597
[2024-12-08 00:03:11] [32mIntermediate result: 0.3938025  (Index 15)[0m
Epoch: 16, Steps: 263 | Train Loss: 0.5213507 Vali Loss: 0.2864376 Test Loss: 0.3938025
EarlyStopping counter: 3 out of 8
Updating learning rate to 3.717263797195089e-05
	iters: 100, epoch: 17 | loss: 0.5729604
	speed: 0.3795s/iter; left time: 8346.3615s
	iters: 200, epoch: 17 | loss: 0.3901150
	speed: 0.1564s/iter; left time: 3423.1531s
Epoch: 17 cost time: 41.871336221694946
[2024-12-08 00:04:07] [32mIntermediate result: 0.39644495  (Index 16)[0m
Epoch: 17, Steps: 263 | Train Loss: 0.5167655 Vali Loss: 0.2880705 Test Loss: 0.3964449
EarlyStopping counter: 4 out of 8
Updating learning rate to 4.0800546925960564e-05
	iters: 100, epoch: 18 | loss: 0.4648080
	speed: 0.3918s/iter; left time: 8513.0181s
	iters: 200, epoch: 18 | loss: 0.5286406
	speed: 0.1558s/iter; left time: 3370.1775s
Epoch: 18 cost time: 41.092379570007324
[2024-12-08 00:05:00] [32mIntermediate result: 0.3980058  (Index 17)[0m
Epoch: 18, Steps: 263 | Train Loss: 0.5120518 Vali Loss: 0.2879360 Test Loss: 0.3980058
EarlyStopping counter: 5 out of 8
Updating learning rate to 4.4497517354552114e-05
	iters: 100, epoch: 19 | loss: 0.4145892
	speed: 0.3836s/iter; left time: 8234.3851s
	iters: 200, epoch: 19 | loss: 0.4899645
	speed: 0.1545s/iter; left time: 3301.8266s
Epoch: 19 cost time: 40.94433236122131
[2024-12-08 00:05:55] [32mIntermediate result: 0.40020403  (Index 18)[0m
Epoch: 19, Steps: 263 | Train Loss: 0.5070329 Vali Loss: 0.2879124 Test Loss: 0.4002040
EarlyStopping counter: 6 out of 8
Updating learning rate to 4.824075187399651e-05
	iters: 100, epoch: 20 | loss: 0.5218198
	speed: 0.3894s/iter; left time: 8255.9732s
	iters: 200, epoch: 20 | loss: 0.3845538
	speed: 0.1492s/iter; left time: 3148.7836s
Epoch: 20 cost time: 39.92797613143921
[2024-12-08 00:06:48] [32mIntermediate result: 0.40421957  (Index 19)[0m
Epoch: 20, Steps: 263 | Train Loss: 0.5014568 Vali Loss: 0.2883898 Test Loss: 0.4042196
EarlyStopping counter: 7 out of 8
Updating learning rate to 5.200716781285351e-05
	iters: 100, epoch: 21 | loss: 0.5981357
	speed: 0.3813s/iter; left time: 7984.9891s
	iters: 200, epoch: 21 | loss: 0.6687962
	speed: 0.1540s/iter; left time: 3208.8191s
Epoch: 21 cost time: 40.906763792037964
[2024-12-08 00:07:43] [32mIntermediate result: 0.40759304  (Index 20)[0m
Epoch: 21, Steps: 263 | Train Loss: 0.4964979 Vali Loss: 0.2905762 Test Loss: 0.4075930
EarlyStopping counter: 8 out of 8
Early stopping
>>>>>>>testing : 24_2_2_96_720_MGSformer_TST_ETTm2_ftM_sl96_ll18_pl720_dm80_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.39244329929351807, mae:0.3956183195114136, rse:0.5029658079147339
[2024-12-08 00:07:53] [32mFinal result: 0.3924433[0m
