Args in experiment:
Namespace(accumulation_steps=2, activation='gelu', affine=0, batch_size=48, c_out=7, checkpoints='./checkpoints/', compress_len=10, d_ff=128, d_layers=1, d_model=16, data='custom', data_path='national_illness.csv', dec_in=7, decomposition=0, des='Exp', device_ids=[0, 1, 2], devices='0,1,2', distil=True, do_predict=False, dropout=0.3, dvices='0,1,2', e_layers=3, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0025, loss='mse', lradj='constant', model='MGSformer_TST', model_id='36_36', momentum=0.8, moving_avg=25, n=1, n_heads=4, n_intra=1, num_workers=10, output_attention=False, padding_patch='end', patch_len=24, patience=8, pct_start=0.3, period=24, pred_len=36, random_seed=2021, revin=1, root_path='./dataset/', seq_len=36, stride=2, subtract_last=0, target='OT', test_flop=False, traffic=0, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=True, x=5)
Use GPU: cuda:0
>>>>>>>start training : 24_1_1_36_36_MGSformer_TST_custom_ftM_sl36_ll18_pl36_dm20_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
module.model.backbone.W_pos_intra: 40
module.model.backbone.W_pos: 480
module.model.backbone.W_pos_coarse: 140
module.model.backbone.W_P_intra.weight: 960
module.model.backbone.W_P_intra.bias: 20
module.model.backbone.W_P.weight: 480
module.model.backbone.W_P.bias: 20
module.model.backbone.W_P_coarse.weight: 1400
module.model.backbone.W_P_coarse.bias: 20
module.model.backbone.encoder.layers.0.self_attn.W_Q.weight: 400
module.model.backbone.encoder.layers.0.self_attn.W_Q.bias: 20
module.model.backbone.encoder.layers.0.self_attn.W_K.weight: 400
module.model.backbone.encoder.layers.0.self_attn.W_K.bias: 20
module.model.backbone.encoder.layers.0.self_attn.W_V.weight: 400
module.model.backbone.encoder.layers.0.self_attn.W_V.bias: 20
module.model.backbone.encoder.layers.0.self_attn.to_out.0.weight: 400
module.model.backbone.encoder.layers.0.self_attn.to_out.0.bias: 20
module.model.backbone.encoder.layers.0.norm_attn.1.weight: 20
module.model.backbone.encoder.layers.0.norm_attn.1.bias: 20
module.model.backbone.encoder.layers.0.ff.0.weight: 2560
module.model.backbone.encoder.layers.0.ff.0.bias: 128
module.model.backbone.encoder.layers.0.ff.3.weight: 2560
module.model.backbone.encoder.layers.0.ff.3.bias: 20
module.model.backbone.encoder.layers.0.norm_ffn.1.weight: 20
module.model.backbone.encoder.layers.0.norm_ffn.1.bias: 20
module.model.backbone.encoder.layers.1.self_attn.W_Q.weight: 400
module.model.backbone.encoder.layers.1.self_attn.W_Q.bias: 20
module.model.backbone.encoder.layers.1.self_attn.W_K.weight: 400
module.model.backbone.encoder.layers.1.self_attn.W_K.bias: 20
module.model.backbone.encoder.layers.1.self_attn.W_V.weight: 400
module.model.backbone.encoder.layers.1.self_attn.W_V.bias: 20
module.model.backbone.encoder.layers.1.self_attn.to_out.0.weight: 400
module.model.backbone.encoder.layers.1.self_attn.to_out.0.bias: 20
module.model.backbone.encoder.layers.1.norm_attn.1.weight: 20
module.model.backbone.encoder.layers.1.norm_attn.1.bias: 20
module.model.backbone.encoder.layers.1.ff.0.weight: 2560
module.model.backbone.encoder.layers.1.ff.0.bias: 128
module.model.backbone.encoder.layers.1.ff.3.weight: 2560
module.model.backbone.encoder.layers.1.ff.3.bias: 20
module.model.backbone.encoder.layers.1.norm_ffn.1.weight: 20
module.model.backbone.encoder.layers.1.norm_ffn.1.bias: 20
module.model.backbone.encoder.layers.2.self_attn.W_Q.weight: 400
module.model.backbone.encoder.layers.2.self_attn.W_Q.bias: 20
module.model.backbone.encoder.layers.2.self_attn.W_K.weight: 400
module.model.backbone.encoder.layers.2.self_attn.W_K.bias: 20
module.model.backbone.encoder.layers.2.self_attn.W_V.weight: 400
module.model.backbone.encoder.layers.2.self_attn.W_V.bias: 20
module.model.backbone.encoder.layers.2.self_attn.to_out.0.weight: 400
module.model.backbone.encoder.layers.2.self_attn.to_out.0.bias: 20
module.model.backbone.encoder.layers.2.norm_attn.1.weight: 20
module.model.backbone.encoder.layers.2.norm_attn.1.bias: 20
module.model.backbone.encoder.layers.2.ff.0.weight: 2560
module.model.backbone.encoder.layers.2.ff.0.bias: 128
module.model.backbone.encoder.layers.2.ff.3.weight: 2560
module.model.backbone.encoder.layers.2.ff.3.bias: 20
module.model.backbone.encoder.layers.2.norm_ffn.1.weight: 20
module.model.backbone.encoder.layers.2.norm_ffn.1.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_intra.layers.0.norm_attn.1.weight: 20
module.model.backbone.encoder_intra.layers.0.norm_attn.1.bias: 20
module.model.backbone.encoder_intra.layers.0.ff.0.weight: 2560
module.model.backbone.encoder_intra.layers.0.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.0.ff.3.weight: 2560
module.model.backbone.encoder_intra.layers.0.ff.3.bias: 20
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.weight: 20
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.W_Q.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.W_Q.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.W_K.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.W_K.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.W_V.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.W_V.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_intra.layers.1.norm_attn.1.weight: 20
module.model.backbone.encoder_intra.layers.1.norm_attn.1.bias: 20
module.model.backbone.encoder_intra.layers.1.ff.0.weight: 2560
module.model.backbone.encoder_intra.layers.1.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.1.ff.3.weight: 2560
module.model.backbone.encoder_intra.layers.1.ff.3.bias: 20
module.model.backbone.encoder_intra.layers.1.norm_ffn.1.weight: 20
module.model.backbone.encoder_intra.layers.1.norm_ffn.1.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.W_Q.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.W_Q.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.W_K.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.W_K.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.W_V.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.W_V.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_intra.layers.2.norm_attn.1.weight: 20
module.model.backbone.encoder_intra.layers.2.norm_attn.1.bias: 20
module.model.backbone.encoder_intra.layers.2.ff.0.weight: 2560
module.model.backbone.encoder_intra.layers.2.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.2.ff.3.weight: 2560
module.model.backbone.encoder_intra.layers.2.ff.3.bias: 20
module.model.backbone.encoder_intra.layers.2.norm_ffn.1.weight: 20
module.model.backbone.encoder_intra.layers.2.norm_ffn.1.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.weight: 20
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.bias: 20
module.model.backbone.encoder_coarse.layers.0.ff.0.weight: 2560
module.model.backbone.encoder_coarse.layers.0.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.0.ff.3.weight: 2560
module.model.backbone.encoder_coarse.layers.0.ff.3.bias: 20
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.weight: 20
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.W_Q.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_Q.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.W_K.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_K.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.W_V.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_V.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_coarse.layers.1.norm_attn.1.weight: 20
module.model.backbone.encoder_coarse.layers.1.norm_attn.1.bias: 20
module.model.backbone.encoder_coarse.layers.1.ff.0.weight: 2560
module.model.backbone.encoder_coarse.layers.1.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.1.ff.3.weight: 2560
module.model.backbone.encoder_coarse.layers.1.ff.3.bias: 20
module.model.backbone.encoder_coarse.layers.1.norm_ffn.1.weight: 20
module.model.backbone.encoder_coarse.layers.1.norm_ffn.1.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.W_Q.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_Q.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.W_K.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_K.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.W_V.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_V.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_coarse.layers.2.norm_attn.1.weight: 20
module.model.backbone.encoder_coarse.layers.2.norm_attn.1.bias: 20
module.model.backbone.encoder_coarse.layers.2.ff.0.weight: 2560
module.model.backbone.encoder_coarse.layers.2.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.2.ff.3.weight: 2560
module.model.backbone.encoder_coarse.layers.2.ff.3.bias: 20
module.model.backbone.encoder_coarse.layers.2.norm_ffn.1.weight: 20
module.model.backbone.encoder_coarse.layers.2.norm_ffn.1.bias: 20
module.model.head.linear.weight: 36720
module.model.head.linear.bias: 36
module.model.compress.weight: 360
module.model.compress.bias: 10
Total trainable parameters: 103938
train 605
val 62
test 158
Epoch: 1 cost time: 3.472337484359741
[2024-12-08 00:11:33] [32mIntermediate result: 3.9568055  (Index 0)[0m
Epoch: 1, Steps: 12 | Train Loss: 1.1272771 Vali Loss: 0.6415501 Test Loss: 3.9568055
Validation loss decreased (inf --> 0.641550).  Saving model ...
Updating learning rate to 0.0025
Epoch: 2 cost time: 2.1651391983032227
[2024-12-08 00:11:36] [32mIntermediate result: 3.6703866  (Index 1)[0m
Epoch: 2, Steps: 12 | Train Loss: 1.0723519 Vali Loss: 0.5934334 Test Loss: 3.6703866
Validation loss decreased (0.641550 --> 0.593433).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 2.115096092224121
[2024-12-08 00:11:39] [32mIntermediate result: 2.362469  (Index 2)[0m
Epoch: 3, Steps: 12 | Train Loss: 0.8554664 Vali Loss: 0.3495532 Test Loss: 2.3624690
Validation loss decreased (0.593433 --> 0.349553).  Saving model ...
Updating learning rate to 0.0025
Epoch: 4 cost time: 2.5004873275756836
[2024-12-08 00:11:43] [32mIntermediate result: 2.642998  (Index 3)[0m
Epoch: 4, Steps: 12 | Train Loss: 0.7800569 Vali Loss: 0.4006107 Test Loss: 2.6429980
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0025
Epoch: 5 cost time: 2.292616367340088
[2024-12-08 00:11:46] [32mIntermediate result: 2.652386  (Index 4)[0m
Epoch: 5, Steps: 12 | Train Loss: 0.7176744 Vali Loss: 0.3987011 Test Loss: 2.6523860
EarlyStopping counter: 2 out of 8
Updating learning rate to 0.0025
Epoch: 6 cost time: 2.341822624206543
[2024-12-08 00:11:49] [32mIntermediate result: 2.3116498  (Index 5)[0m
Epoch: 6, Steps: 12 | Train Loss: 0.6807613 Vali Loss: 0.3482386 Test Loss: 2.3116498
Validation loss decreased (0.349553 --> 0.348239).  Saving model ...
Updating learning rate to 0.0025
Epoch: 7 cost time: 2.1712470054626465
[2024-12-08 00:11:53] [32mIntermediate result: 2.5890598  (Index 6)[0m
Epoch: 7, Steps: 12 | Train Loss: 0.6557545 Vali Loss: 0.3541417 Test Loss: 2.5890598
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0025
Epoch: 8 cost time: 2.3444721698760986
[2024-12-08 00:11:56] [32mIntermediate result: 2.4066892  (Index 7)[0m
Epoch: 8, Steps: 12 | Train Loss: 0.6339316 Vali Loss: 0.2984606 Test Loss: 2.4066892
Validation loss decreased (0.348239 --> 0.298461).  Saving model ...
Updating learning rate to 0.0025
Epoch: 9 cost time: 2.5301811695098877
[2024-12-08 00:12:00] [32mIntermediate result: 2.6701727  (Index 8)[0m
Epoch: 9, Steps: 12 | Train Loss: 0.6082445 Vali Loss: 0.3705318 Test Loss: 2.6701727
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0025
Epoch: 10 cost time: 2.217447280883789
[2024-12-08 00:12:03] [32mIntermediate result: 2.17799  (Index 9)[0m
Epoch: 10, Steps: 12 | Train Loss: 0.5879035 Vali Loss: 0.2639028 Test Loss: 2.1779900
Validation loss decreased (0.298461 --> 0.263903).  Saving model ...
Updating learning rate to 0.0025
Epoch: 11 cost time: 2.4255969524383545
[2024-12-08 00:12:06] [32mIntermediate result: 2.5586329  (Index 10)[0m
Epoch: 11, Steps: 12 | Train Loss: 0.5807288 Vali Loss: 0.3690100 Test Loss: 2.5586329
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0025
Epoch: 12 cost time: 2.3691024780273438
[2024-12-08 00:12:10] [32mIntermediate result: 1.909163  (Index 11)[0m
Epoch: 12, Steps: 12 | Train Loss: 0.5810116 Vali Loss: 0.2605743 Test Loss: 1.9091630
Validation loss decreased (0.263903 --> 0.260574).  Saving model ...
Updating learning rate to 0.0025
Epoch: 13 cost time: 2.461435079574585
[2024-12-08 00:12:13] [32mIntermediate result: 2.220491  (Index 12)[0m
Epoch: 13, Steps: 12 | Train Loss: 0.5436455 Vali Loss: 0.2921444 Test Loss: 2.2204909
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0025
Epoch: 14 cost time: 2.2274222373962402
[2024-12-08 00:12:17] [32mIntermediate result: 1.9862348  (Index 13)[0m
Epoch: 14, Steps: 12 | Train Loss: 0.5393100 Vali Loss: 0.2623611 Test Loss: 1.9862348
EarlyStopping counter: 2 out of 8
Updating learning rate to 0.0025
Epoch: 15 cost time: 2.4023454189300537
[2024-12-08 00:12:20] [32mIntermediate result: 1.8390874  (Index 14)[0m
Epoch: 15, Steps: 12 | Train Loss: 0.5034361 Vali Loss: 0.2390862 Test Loss: 1.8390874
Validation loss decreased (0.260574 --> 0.239086).  Saving model ...
Updating learning rate to 0.0025
Epoch: 16 cost time: 2.2404441833496094
[2024-12-08 00:12:23] [32mIntermediate result: 1.8219868  (Index 15)[0m
Epoch: 16, Steps: 12 | Train Loss: 0.5118040 Vali Loss: 0.2606165 Test Loss: 1.8219868
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0025
Epoch: 17 cost time: 2.146052837371826
[2024-12-08 00:12:26] [32mIntermediate result: 1.9144721  (Index 16)[0m
Epoch: 17, Steps: 12 | Train Loss: 0.4970562 Vali Loss: 0.2479071 Test Loss: 1.9144721
EarlyStopping counter: 2 out of 8
Updating learning rate to 0.0025
Epoch: 18 cost time: 2.1268463134765625
[2024-12-08 00:12:30] [32mIntermediate result: 1.645258  (Index 17)[0m
Epoch: 18, Steps: 12 | Train Loss: 0.4832788 Vali Loss: 0.2303174 Test Loss: 1.6452579
Validation loss decreased (0.239086 --> 0.230317).  Saving model ...
Updating learning rate to 0.0025
Epoch: 19 cost time: 2.246997117996216
[2024-12-08 00:12:33] [32mIntermediate result: 1.777757  (Index 18)[0m
Epoch: 19, Steps: 12 | Train Loss: 0.4912585 Vali Loss: 0.2448139 Test Loss: 1.7777570
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0025
Epoch: 20 cost time: 2.448775053024292
[2024-12-08 00:12:36] [32mIntermediate result: 1.7399712  (Index 19)[0m
Epoch: 20, Steps: 12 | Train Loss: 0.4761862 Vali Loss: 0.2264580 Test Loss: 1.7399712
Validation loss decreased (0.230317 --> 0.226458).  Saving model ...
Updating learning rate to 0.0025
Epoch: 21 cost time: 2.420574903488159
[2024-12-08 00:12:40] [32mIntermediate result: 1.8318067  (Index 20)[0m
Epoch: 21, Steps: 12 | Train Loss: 0.4705776 Vali Loss: 0.2365140 Test Loss: 1.8318067
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0025
Epoch: 22 cost time: 2.188166379928589
[2024-12-08 00:12:43] [32mIntermediate result: 1.5994626  (Index 21)[0m
Epoch: 22, Steps: 12 | Train Loss: 0.4582088 Vali Loss: 0.2111323 Test Loss: 1.5994626
Validation loss decreased (0.226458 --> 0.211132).  Saving model ...
Updating learning rate to 0.0025
Epoch: 23 cost time: 2.517807960510254
[2024-12-08 00:12:46] [32mIntermediate result: 1.5055146  (Index 22)[0m
Epoch: 23, Steps: 12 | Train Loss: 0.4724983 Vali Loss: 0.2254027 Test Loss: 1.5055146
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.0025
Epoch: 24 cost time: 2.076726198196411
[2024-12-08 00:12:50] [32mIntermediate result: 1.6832389  (Index 23)[0m
Epoch: 24, Steps: 12 | Train Loss: 0.4672072 Vali Loss: 0.2599421 Test Loss: 1.6832389
EarlyStopping counter: 2 out of 8
Updating learning rate to 0.0025
Epoch: 25 cost time: 2.43436861038208
[2024-12-08 00:12:53] [32mIntermediate result: 2.0110328  (Index 24)[0m
Epoch: 25, Steps: 12 | Train Loss: 0.4466454 Vali Loss: 0.2410000 Test Loss: 2.0110328
EarlyStopping counter: 3 out of 8
Updating learning rate to 0.0025
Epoch: 26 cost time: 2.373976469039917
[2024-12-08 00:12:57] [32mIntermediate result: 1.5494348  (Index 25)[0m
Epoch: 26, Steps: 12 | Train Loss: 0.4440336 Vali Loss: 0.2264168 Test Loss: 1.5494348
EarlyStopping counter: 4 out of 8
Updating learning rate to 0.0025
Epoch: 27 cost time: 2.3076906204223633
[2024-12-08 00:13:00] [32mIntermediate result: 1.9143318  (Index 26)[0m
Epoch: 27, Steps: 12 | Train Loss: 0.4547130 Vali Loss: 0.2628114 Test Loss: 1.9143318
EarlyStopping counter: 5 out of 8
Updating learning rate to 0.0025
Epoch: 28 cost time: 2.118924856185913
[2024-12-08 00:13:03] [32mIntermediate result: 1.5994524  (Index 27)[0m
Epoch: 28, Steps: 12 | Train Loss: 0.4477147 Vali Loss: 0.2159407 Test Loss: 1.5994524
EarlyStopping counter: 6 out of 8
Updating learning rate to 0.0025
Epoch: 29 cost time: 2.458420753479004
[2024-12-08 00:13:06] [32mIntermediate result: 1.7300491  (Index 28)[0m
Epoch: 29, Steps: 12 | Train Loss: 0.4329165 Vali Loss: 0.2350288 Test Loss: 1.7300491
EarlyStopping counter: 7 out of 8
Updating learning rate to 0.0025
Epoch: 30 cost time: 2.3826966285705566
[2024-12-08 00:13:10] [32mIntermediate result: 1.624158  (Index 29)[0m
Epoch: 30, Steps: 12 | Train Loss: 0.4489573 Vali Loss: 0.2700578 Test Loss: 1.6241580
EarlyStopping counter: 8 out of 8
Early stopping
>>>>>>>testing : 24_1_1_36_36_MGSformer_TST_custom_ftM_sl36_ll18_pl36_dm20_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 158
mse:1.599462628364563, mae:0.818933367729187, rse:0.6065589785575867
[2024-12-08 00:13:11] [32mFinal result: 1.5994626[0m
