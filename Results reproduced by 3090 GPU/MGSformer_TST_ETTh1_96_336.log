Args in experiment:
Namespace(accumulation_steps=2, activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', compress_len=10, d_ff=128, d_layers=1, d_model=16, data='ETTh1', data_path='ETTh1.csv', dec_in=7, decomposition=0, des='Exp', device_ids=[0, 1, 2], devices='0,1,2', distil=True, do_predict=False, dropout=0.3, dvices='0,1,2', e_layers=3, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='type3', model='MGSformer_TST', model_id='96_336', momentum=0.8, moving_avg=25, n=2, n_heads=4, n_intra=2, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=8, pct_start=0.3, period=24, pred_len=336, random_seed=2021, revin=1, root_path='./dataset/', seq_len=96, stride=8, subtract_last=0, target='OT', test_flop=False, traffic=0, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=True, x=5)
Use GPU: cuda:0
>>>>>>>start training : 24_2_2_96_336_MGSformer_TST_ETTh1_ftM_sl96_ll18_pl336_dm20_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
module.model.backbone.W_pos_intra: 80
module.model.backbone.W_pos: 480
module.model.backbone.W_pos_coarse: 140
module.model.backbone.W_P_intra.weight: 960
module.model.backbone.W_P_intra.bias: 20
module.model.backbone.W_P.weight: 240
module.model.backbone.W_P.bias: 20
module.model.backbone.W_P_coarse.weight: 1400
module.model.backbone.W_P_coarse.bias: 20
module.model.backbone.encoder.layers.0.self_attn.W_Q.weight: 400
module.model.backbone.encoder.layers.0.self_attn.W_Q.bias: 20
module.model.backbone.encoder.layers.0.self_attn.W_K.weight: 400
module.model.backbone.encoder.layers.0.self_attn.W_K.bias: 20
module.model.backbone.encoder.layers.0.self_attn.W_V.weight: 400
module.model.backbone.encoder.layers.0.self_attn.W_V.bias: 20
module.model.backbone.encoder.layers.0.self_attn.to_out.0.weight: 400
module.model.backbone.encoder.layers.0.self_attn.to_out.0.bias: 20
module.model.backbone.encoder.layers.0.norm_attn.1.weight: 20
module.model.backbone.encoder.layers.0.norm_attn.1.bias: 20
module.model.backbone.encoder.layers.0.ff.0.weight: 2560
module.model.backbone.encoder.layers.0.ff.0.bias: 128
module.model.backbone.encoder.layers.0.ff.3.weight: 2560
module.model.backbone.encoder.layers.0.ff.3.bias: 20
module.model.backbone.encoder.layers.0.norm_ffn.1.weight: 20
module.model.backbone.encoder.layers.0.norm_ffn.1.bias: 20
module.model.backbone.encoder.layers.1.self_attn.W_Q.weight: 400
module.model.backbone.encoder.layers.1.self_attn.W_Q.bias: 20
module.model.backbone.encoder.layers.1.self_attn.W_K.weight: 400
module.model.backbone.encoder.layers.1.self_attn.W_K.bias: 20
module.model.backbone.encoder.layers.1.self_attn.W_V.weight: 400
module.model.backbone.encoder.layers.1.self_attn.W_V.bias: 20
module.model.backbone.encoder.layers.1.self_attn.to_out.0.weight: 400
module.model.backbone.encoder.layers.1.self_attn.to_out.0.bias: 20
module.model.backbone.encoder.layers.1.norm_attn.1.weight: 20
module.model.backbone.encoder.layers.1.norm_attn.1.bias: 20
module.model.backbone.encoder.layers.1.ff.0.weight: 2560
module.model.backbone.encoder.layers.1.ff.0.bias: 128
module.model.backbone.encoder.layers.1.ff.3.weight: 2560
module.model.backbone.encoder.layers.1.ff.3.bias: 20
module.model.backbone.encoder.layers.1.norm_ffn.1.weight: 20
module.model.backbone.encoder.layers.1.norm_ffn.1.bias: 20
module.model.backbone.encoder.layers.2.self_attn.W_Q.weight: 400
module.model.backbone.encoder.layers.2.self_attn.W_Q.bias: 20
module.model.backbone.encoder.layers.2.self_attn.W_K.weight: 400
module.model.backbone.encoder.layers.2.self_attn.W_K.bias: 20
module.model.backbone.encoder.layers.2.self_attn.W_V.weight: 400
module.model.backbone.encoder.layers.2.self_attn.W_V.bias: 20
module.model.backbone.encoder.layers.2.self_attn.to_out.0.weight: 400
module.model.backbone.encoder.layers.2.self_attn.to_out.0.bias: 20
module.model.backbone.encoder.layers.2.norm_attn.1.weight: 20
module.model.backbone.encoder.layers.2.norm_attn.1.bias: 20
module.model.backbone.encoder.layers.2.ff.0.weight: 2560
module.model.backbone.encoder.layers.2.ff.0.bias: 128
module.model.backbone.encoder.layers.2.ff.3.weight: 2560
module.model.backbone.encoder.layers.2.ff.3.bias: 20
module.model.backbone.encoder.layers.2.norm_ffn.1.weight: 20
module.model.backbone.encoder.layers.2.norm_ffn.1.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_intra.layers.0.norm_attn.1.weight: 20
module.model.backbone.encoder_intra.layers.0.norm_attn.1.bias: 20
module.model.backbone.encoder_intra.layers.0.ff.0.weight: 2560
module.model.backbone.encoder_intra.layers.0.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.0.ff.3.weight: 2560
module.model.backbone.encoder_intra.layers.0.ff.3.bias: 20
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.weight: 20
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.W_Q.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.W_Q.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.W_K.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.W_K.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.W_V.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.W_V.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_intra.layers.1.norm_attn.1.weight: 20
module.model.backbone.encoder_intra.layers.1.norm_attn.1.bias: 20
module.model.backbone.encoder_intra.layers.1.ff.0.weight: 2560
module.model.backbone.encoder_intra.layers.1.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.1.ff.3.weight: 2560
module.model.backbone.encoder_intra.layers.1.ff.3.bias: 20
module.model.backbone.encoder_intra.layers.1.norm_ffn.1.weight: 20
module.model.backbone.encoder_intra.layers.1.norm_ffn.1.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.W_Q.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.W_Q.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.W_K.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.W_K.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.W_V.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.W_V.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_intra.layers.2.norm_attn.1.weight: 20
module.model.backbone.encoder_intra.layers.2.norm_attn.1.bias: 20
module.model.backbone.encoder_intra.layers.2.ff.0.weight: 2560
module.model.backbone.encoder_intra.layers.2.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.2.ff.3.weight: 2560
module.model.backbone.encoder_intra.layers.2.ff.3.bias: 20
module.model.backbone.encoder_intra.layers.2.norm_ffn.1.weight: 20
module.model.backbone.encoder_intra.layers.2.norm_ffn.1.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.weight: 20
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.bias: 20
module.model.backbone.encoder_coarse.layers.0.ff.0.weight: 2560
module.model.backbone.encoder_coarse.layers.0.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.0.ff.3.weight: 2560
module.model.backbone.encoder_coarse.layers.0.ff.3.bias: 20
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.weight: 20
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.W_Q.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_Q.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.W_K.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_K.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.W_V.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_V.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_coarse.layers.1.norm_attn.1.weight: 20
module.model.backbone.encoder_coarse.layers.1.norm_attn.1.bias: 20
module.model.backbone.encoder_coarse.layers.1.ff.0.weight: 2560
module.model.backbone.encoder_coarse.layers.1.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.1.ff.3.weight: 2560
module.model.backbone.encoder_coarse.layers.1.ff.3.bias: 20
module.model.backbone.encoder_coarse.layers.1.norm_ffn.1.weight: 20
module.model.backbone.encoder_coarse.layers.1.norm_ffn.1.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.W_Q.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_Q.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.W_K.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_K.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.W_V.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_V.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_coarse.layers.2.norm_attn.1.weight: 20
module.model.backbone.encoder_coarse.layers.2.norm_attn.1.bias: 20
module.model.backbone.encoder_coarse.layers.2.ff.0.weight: 2560
module.model.backbone.encoder_coarse.layers.2.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.2.ff.3.weight: 2560
module.model.backbone.encoder_coarse.layers.2.ff.3.bias: 20
module.model.backbone.encoder_coarse.layers.2.norm_ffn.1.weight: 20
module.model.backbone.encoder_coarse.layers.2.norm_ffn.1.bias: 20
module.model.head.linear.weight: 678720
module.model.head.linear.bias: 336
module.model.compress.weight: 960
module.model.compress.bias: 10
Total trainable parameters: 746638
train 8209
val 2545
test 2545
Epoch: 1 cost time: 10.898657321929932
[2024-12-07 20:22:52] [32mIntermediate result: 0.72756577  (Index 0)[0m
Epoch: 1, Steps: 64 | Train Loss: 0.7587833 Vali Loss: 1.6778549 Test Loss: 0.7275658
Validation loss decreased (inf --> 1.677855).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 9.85313367843628
[2024-12-07 20:23:06] [32mIntermediate result: 0.50379515  (Index 1)[0m
Epoch: 2, Steps: 64 | Train Loss: 0.6039521 Vali Loss: 1.3196102 Test Loss: 0.5037951
Validation loss decreased (1.677855 --> 1.319610).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 10.024165153503418
[2024-12-07 20:23:19] [32mIntermediate result: 0.489626  (Index 2)[0m
Epoch: 3, Steps: 64 | Train Loss: 0.5426563 Vali Loss: 1.3053081 Test Loss: 0.4896260
Validation loss decreased (1.319610 --> 1.305308).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 10.518553972244263
[2024-12-07 20:23:33] [32mIntermediate result: 0.48526135  (Index 3)[0m
Epoch: 4, Steps: 64 | Train Loss: 0.5218850 Vali Loss: 1.3000594 Test Loss: 0.4852614
Validation loss decreased (1.305308 --> 1.300059).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 9.89681625366211
[2024-12-07 20:23:47] [32mIntermediate result: 0.4827459  (Index 4)[0m
Epoch: 5, Steps: 64 | Train Loss: 0.5129276 Vali Loss: 1.3009166 Test Loss: 0.4827459
EarlyStopping counter: 1 out of 8
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 10.176664590835571
[2024-12-07 20:24:01] [32mIntermediate result: 0.4826609  (Index 5)[0m
Epoch: 6, Steps: 64 | Train Loss: 0.5082688 Vali Loss: 1.2927458 Test Loss: 0.4826609
Validation loss decreased (1.300059 --> 1.292746).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 10.354506731033325
[2024-12-07 20:24:15] [32mIntermediate result: 0.4805338  (Index 6)[0m
Epoch: 7, Steps: 64 | Train Loss: 0.5047975 Vali Loss: 1.2968967 Test Loss: 0.4805338
EarlyStopping counter: 1 out of 8
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 10.232235670089722
[2024-12-07 20:24:29] [32mIntermediate result: 0.47932047  (Index 7)[0m
Epoch: 8, Steps: 64 | Train Loss: 0.5018775 Vali Loss: 1.3003238 Test Loss: 0.4793205
EarlyStopping counter: 2 out of 8
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 10.105723857879639
[2024-12-07 20:24:43] [32mIntermediate result: 0.4806933  (Index 8)[0m
Epoch: 9, Steps: 64 | Train Loss: 0.4998249 Vali Loss: 1.2889167 Test Loss: 0.4806933
Validation loss decreased (1.292746 --> 1.288917).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 10.106880903244019
[2024-12-07 20:24:57] [32mIntermediate result: 0.47881502  (Index 9)[0m
Epoch: 10, Steps: 64 | Train Loss: 0.4978563 Vali Loss: 1.2941710 Test Loss: 0.4788150
EarlyStopping counter: 1 out of 8
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 10.35113000869751
[2024-12-07 20:25:11] [32mIntermediate result: 0.47796193  (Index 10)[0m
Epoch: 11, Steps: 64 | Train Loss: 0.4965025 Vali Loss: 1.2990880 Test Loss: 0.4779619
EarlyStopping counter: 2 out of 8
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 10.2759850025177
[2024-12-07 20:25:25] [32mIntermediate result: 0.47786245  (Index 11)[0m
Epoch: 12, Steps: 64 | Train Loss: 0.4951919 Vali Loss: 1.2947552 Test Loss: 0.4778624
EarlyStopping counter: 3 out of 8
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 10.606537818908691
[2024-12-07 20:25:39] [32mIntermediate result: 0.47860584  (Index 12)[0m
Epoch: 13, Steps: 64 | Train Loss: 0.4939064 Vali Loss: 1.2935747 Test Loss: 0.4786058
EarlyStopping counter: 4 out of 8
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 10.268490552902222
[2024-12-07 20:25:53] [32mIntermediate result: 0.47789493  (Index 13)[0m
Epoch: 14, Steps: 64 | Train Loss: 0.4929149 Vali Loss: 1.2937651 Test Loss: 0.4778949
EarlyStopping counter: 5 out of 8
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 10.469400644302368
[2024-12-07 20:26:07] [32mIntermediate result: 0.47756693  (Index 14)[0m
Epoch: 15, Steps: 64 | Train Loss: 0.4921691 Vali Loss: 1.2944546 Test Loss: 0.4775669
EarlyStopping counter: 6 out of 8
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 9.737430334091187
[2024-12-07 20:26:20] [32mIntermediate result: 0.47773322  (Index 15)[0m
Epoch: 16, Steps: 64 | Train Loss: 0.4912596 Vali Loss: 1.2946481 Test Loss: 0.4777332
EarlyStopping counter: 7 out of 8
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 10.318756580352783
[2024-12-07 20:26:34] [32mIntermediate result: 0.47805125  (Index 16)[0m
Epoch: 17, Steps: 64 | Train Loss: 0.4905666 Vali Loss: 1.2910355 Test Loss: 0.4780512
EarlyStopping counter: 8 out of 8
Early stopping
>>>>>>>testing : 24_2_2_96_336_MGSformer_TST_ETTh1_ftM_sl96_ll18_pl336_dm20_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.4806932806968689, mae:0.4457910656929016, rse:0.6627665162086487
[2024-12-07 20:26:37] [32mFinal result: 0.48069328[0m
