Args in experiment:
Namespace(accumulation_steps=2, activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', compress_len=10, d_ff=128, d_layers=1, d_model=16, data='ETTh2', data_path='ETTh2.csv', dec_in=7, decomposition=0, des='Exp', device_ids=[0, 1, 2], devices='0,1,2', distil=True, do_predict=False, dropout=0.3, dvices='0,1,2', e_layers=3, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='type3', model='MGSformer_TST', model_id='96_192', momentum=0.8, moving_avg=25, n=2, n_heads=4, n_intra=2, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=8, pct_start=0.3, period=24, pred_len=192, random_seed=2021, revin=1, root_path='./dataset/', seq_len=96, stride=8, subtract_last=0, target='OT', test_flop=False, traffic=0, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=True, x=5)
Use GPU: cuda:0
>>>>>>>start training : 24_2_2_96_192_MGSformer_TST_ETTh2_ftM_sl96_ll18_pl192_dm20_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
module.model.backbone.W_pos_intra: 80
module.model.backbone.W_pos: 480
module.model.backbone.W_pos_coarse: 140
module.model.backbone.W_P_intra.weight: 960
module.model.backbone.W_P_intra.bias: 20
module.model.backbone.W_P.weight: 240
module.model.backbone.W_P.bias: 20
module.model.backbone.W_P_coarse.weight: 1400
module.model.backbone.W_P_coarse.bias: 20
module.model.backbone.encoder.layers.0.self_attn.W_Q.weight: 400
module.model.backbone.encoder.layers.0.self_attn.W_Q.bias: 20
module.model.backbone.encoder.layers.0.self_attn.W_K.weight: 400
module.model.backbone.encoder.layers.0.self_attn.W_K.bias: 20
module.model.backbone.encoder.layers.0.self_attn.W_V.weight: 400
module.model.backbone.encoder.layers.0.self_attn.W_V.bias: 20
module.model.backbone.encoder.layers.0.self_attn.to_out.0.weight: 400
module.model.backbone.encoder.layers.0.self_attn.to_out.0.bias: 20
module.model.backbone.encoder.layers.0.norm_attn.1.weight: 20
module.model.backbone.encoder.layers.0.norm_attn.1.bias: 20
module.model.backbone.encoder.layers.0.ff.0.weight: 2560
module.model.backbone.encoder.layers.0.ff.0.bias: 128
module.model.backbone.encoder.layers.0.ff.3.weight: 2560
module.model.backbone.encoder.layers.0.ff.3.bias: 20
module.model.backbone.encoder.layers.0.norm_ffn.1.weight: 20
module.model.backbone.encoder.layers.0.norm_ffn.1.bias: 20
module.model.backbone.encoder.layers.1.self_attn.W_Q.weight: 400
module.model.backbone.encoder.layers.1.self_attn.W_Q.bias: 20
module.model.backbone.encoder.layers.1.self_attn.W_K.weight: 400
module.model.backbone.encoder.layers.1.self_attn.W_K.bias: 20
module.model.backbone.encoder.layers.1.self_attn.W_V.weight: 400
module.model.backbone.encoder.layers.1.self_attn.W_V.bias: 20
module.model.backbone.encoder.layers.1.self_attn.to_out.0.weight: 400
module.model.backbone.encoder.layers.1.self_attn.to_out.0.bias: 20
module.model.backbone.encoder.layers.1.norm_attn.1.weight: 20
module.model.backbone.encoder.layers.1.norm_attn.1.bias: 20
module.model.backbone.encoder.layers.1.ff.0.weight: 2560
module.model.backbone.encoder.layers.1.ff.0.bias: 128
module.model.backbone.encoder.layers.1.ff.3.weight: 2560
module.model.backbone.encoder.layers.1.ff.3.bias: 20
module.model.backbone.encoder.layers.1.norm_ffn.1.weight: 20
module.model.backbone.encoder.layers.1.norm_ffn.1.bias: 20
module.model.backbone.encoder.layers.2.self_attn.W_Q.weight: 400
module.model.backbone.encoder.layers.2.self_attn.W_Q.bias: 20
module.model.backbone.encoder.layers.2.self_attn.W_K.weight: 400
module.model.backbone.encoder.layers.2.self_attn.W_K.bias: 20
module.model.backbone.encoder.layers.2.self_attn.W_V.weight: 400
module.model.backbone.encoder.layers.2.self_attn.W_V.bias: 20
module.model.backbone.encoder.layers.2.self_attn.to_out.0.weight: 400
module.model.backbone.encoder.layers.2.self_attn.to_out.0.bias: 20
module.model.backbone.encoder.layers.2.norm_attn.1.weight: 20
module.model.backbone.encoder.layers.2.norm_attn.1.bias: 20
module.model.backbone.encoder.layers.2.ff.0.weight: 2560
module.model.backbone.encoder.layers.2.ff.0.bias: 128
module.model.backbone.encoder.layers.2.ff.3.weight: 2560
module.model.backbone.encoder.layers.2.ff.3.bias: 20
module.model.backbone.encoder.layers.2.norm_ffn.1.weight: 20
module.model.backbone.encoder.layers.2.norm_ffn.1.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_intra.layers.0.norm_attn.1.weight: 20
module.model.backbone.encoder_intra.layers.0.norm_attn.1.bias: 20
module.model.backbone.encoder_intra.layers.0.ff.0.weight: 2560
module.model.backbone.encoder_intra.layers.0.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.0.ff.3.weight: 2560
module.model.backbone.encoder_intra.layers.0.ff.3.bias: 20
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.weight: 20
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.W_Q.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.W_Q.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.W_K.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.W_K.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.W_V.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.W_V.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_intra.layers.1.norm_attn.1.weight: 20
module.model.backbone.encoder_intra.layers.1.norm_attn.1.bias: 20
module.model.backbone.encoder_intra.layers.1.ff.0.weight: 2560
module.model.backbone.encoder_intra.layers.1.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.1.ff.3.weight: 2560
module.model.backbone.encoder_intra.layers.1.ff.3.bias: 20
module.model.backbone.encoder_intra.layers.1.norm_ffn.1.weight: 20
module.model.backbone.encoder_intra.layers.1.norm_ffn.1.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.W_Q.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.W_Q.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.W_K.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.W_K.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.W_V.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.W_V.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_intra.layers.2.norm_attn.1.weight: 20
module.model.backbone.encoder_intra.layers.2.norm_attn.1.bias: 20
module.model.backbone.encoder_intra.layers.2.ff.0.weight: 2560
module.model.backbone.encoder_intra.layers.2.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.2.ff.3.weight: 2560
module.model.backbone.encoder_intra.layers.2.ff.3.bias: 20
module.model.backbone.encoder_intra.layers.2.norm_ffn.1.weight: 20
module.model.backbone.encoder_intra.layers.2.norm_ffn.1.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.weight: 20
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.bias: 20
module.model.backbone.encoder_coarse.layers.0.ff.0.weight: 2560
module.model.backbone.encoder_coarse.layers.0.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.0.ff.3.weight: 2560
module.model.backbone.encoder_coarse.layers.0.ff.3.bias: 20
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.weight: 20
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.W_Q.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_Q.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.W_K.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_K.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.W_V.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_V.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_coarse.layers.1.norm_attn.1.weight: 20
module.model.backbone.encoder_coarse.layers.1.norm_attn.1.bias: 20
module.model.backbone.encoder_coarse.layers.1.ff.0.weight: 2560
module.model.backbone.encoder_coarse.layers.1.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.1.ff.3.weight: 2560
module.model.backbone.encoder_coarse.layers.1.ff.3.bias: 20
module.model.backbone.encoder_coarse.layers.1.norm_ffn.1.weight: 20
module.model.backbone.encoder_coarse.layers.1.norm_ffn.1.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.W_Q.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_Q.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.W_K.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_K.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.W_V.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_V.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_coarse.layers.2.norm_attn.1.weight: 20
module.model.backbone.encoder_coarse.layers.2.norm_attn.1.bias: 20
module.model.backbone.encoder_coarse.layers.2.ff.0.weight: 2560
module.model.backbone.encoder_coarse.layers.2.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.2.ff.3.weight: 2560
module.model.backbone.encoder_coarse.layers.2.ff.3.bias: 20
module.model.backbone.encoder_coarse.layers.2.norm_ffn.1.weight: 20
module.model.backbone.encoder_coarse.layers.2.norm_ffn.1.bias: 20
module.model.head.linear.weight: 387840
module.model.head.linear.bias: 192
module.model.compress.weight: 960
module.model.compress.bias: 10
Total trainable parameters: 455614
train 8353
val 2689
test 2689
Epoch: 1 cost time: 11.888550043106079
[2024-12-07 20:40:31] [32mIntermediate result: 0.44387212  (Index 0)[0m
Epoch: 1, Steps: 65 | Train Loss: 0.6798613 Vali Loss: 0.3319715 Test Loss: 0.4438721
Validation loss decreased (inf --> 0.331971).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 10.755772352218628
[2024-12-07 20:40:45] [32mIntermediate result: 0.39183554  (Index 1)[0m
Epoch: 2, Steps: 65 | Train Loss: 0.6123374 Vali Loss: 0.2865480 Test Loss: 0.3918355
Validation loss decreased (0.331971 --> 0.286548).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 10.755361080169678
[2024-12-07 20:41:00] [32mIntermediate result: 0.38125783  (Index 2)[0m
Epoch: 3, Steps: 65 | Train Loss: 0.5793753 Vali Loss: 0.2803029 Test Loss: 0.3812578
Validation loss decreased (0.286548 --> 0.280303).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 10.71300220489502
[2024-12-07 20:41:14] [32mIntermediate result: 0.37859294  (Index 3)[0m
Epoch: 4, Steps: 65 | Train Loss: 0.5634980 Vali Loss: 0.2803184 Test Loss: 0.3785929
EarlyStopping counter: 1 out of 8
Updating learning rate to 9e-05
Epoch: 5 cost time: 10.53408145904541
[2024-12-07 20:41:28] [32mIntermediate result: 0.37597317  (Index 4)[0m
Epoch: 5, Steps: 65 | Train Loss: 0.5541867 Vali Loss: 0.2798317 Test Loss: 0.3759732
Validation loss decreased (0.280303 --> 0.279832).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 10.506375074386597
[2024-12-07 20:41:43] [32mIntermediate result: 0.3716635  (Index 5)[0m
Epoch: 6, Steps: 65 | Train Loss: 0.5442885 Vali Loss: 0.2775042 Test Loss: 0.3716635
Validation loss decreased (0.279832 --> 0.277504).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 10.614767074584961
[2024-12-07 20:41:57] [32mIntermediate result: 0.3720546  (Index 6)[0m
Epoch: 7, Steps: 65 | Train Loss: 0.5370643 Vali Loss: 0.2791403 Test Loss: 0.3720546
EarlyStopping counter: 1 out of 8
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 10.551801681518555
[2024-12-07 20:42:12] [32mIntermediate result: 0.36908898  (Index 7)[0m
Epoch: 8, Steps: 65 | Train Loss: 0.5319661 Vali Loss: 0.2769876 Test Loss: 0.3690890
Validation loss decreased (0.277504 --> 0.276988).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 10.614500761032104
[2024-12-07 20:42:26] [32mIntermediate result: 0.36938748  (Index 8)[0m
Epoch: 9, Steps: 65 | Train Loss: 0.5279273 Vali Loss: 0.2766853 Test Loss: 0.3693875
Validation loss decreased (0.276988 --> 0.276685).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 10.404977798461914
[2024-12-07 20:42:40] [32mIntermediate result: 0.3698297  (Index 9)[0m
Epoch: 10, Steps: 65 | Train Loss: 0.5217203 Vali Loss: 0.2778971 Test Loss: 0.3698297
EarlyStopping counter: 1 out of 8
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 10.389604806900024
[2024-12-07 20:42:55] [32mIntermediate result: 0.36949676  (Index 10)[0m
Epoch: 11, Steps: 65 | Train Loss: 0.5195343 Vali Loss: 0.2777979 Test Loss: 0.3694968
EarlyStopping counter: 2 out of 8
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 10.747440099716187
[2024-12-07 20:43:09] [32mIntermediate result: 0.36924025  (Index 11)[0m
Epoch: 12, Steps: 65 | Train Loss: 0.5137137 Vali Loss: 0.2770637 Test Loss: 0.3692403
EarlyStopping counter: 3 out of 8
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 10.717163801193237
[2024-12-07 20:43:24] [32mIntermediate result: 0.3680619  (Index 12)[0m
Epoch: 13, Steps: 65 | Train Loss: 0.5114438 Vali Loss: 0.2759525 Test Loss: 0.3680619
Validation loss decreased (0.276685 --> 0.275952).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 10.455634593963623
[2024-12-07 20:43:38] [32mIntermediate result: 0.36679465  (Index 13)[0m
Epoch: 14, Steps: 65 | Train Loss: 0.5075454 Vali Loss: 0.2748078 Test Loss: 0.3667946
Validation loss decreased (0.275952 --> 0.274808).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 10.99544882774353
[2024-12-07 20:43:54] [32mIntermediate result: 0.3674776  (Index 14)[0m
Epoch: 15, Steps: 65 | Train Loss: 0.5073427 Vali Loss: 0.2749625 Test Loss: 0.3674776
EarlyStopping counter: 1 out of 8
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 10.659906387329102
[2024-12-07 20:44:08] [32mIntermediate result: 0.36748624  (Index 15)[0m
Epoch: 16, Steps: 65 | Train Loss: 0.5043555 Vali Loss: 0.2749803 Test Loss: 0.3674862
EarlyStopping counter: 2 out of 8
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 10.769636869430542
[2024-12-07 20:44:23] [32mIntermediate result: 0.3668854  (Index 16)[0m
Epoch: 17, Steps: 65 | Train Loss: 0.5001151 Vali Loss: 0.2744613 Test Loss: 0.3668854
Validation loss decreased (0.274808 --> 0.274461).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 10.754907131195068
[2024-12-07 20:44:38] [32mIntermediate result: 0.3669903  (Index 17)[0m
Epoch: 18, Steps: 65 | Train Loss: 0.4977642 Vali Loss: 0.2743473 Test Loss: 0.3669903
Validation loss decreased (0.274461 --> 0.274347).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 10.614237785339355
[2024-12-07 20:44:52] [32mIntermediate result: 0.36731496  (Index 18)[0m
Epoch: 19, Steps: 65 | Train Loss: 0.4987246 Vali Loss: 0.2746274 Test Loss: 0.3673150
EarlyStopping counter: 1 out of 8
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 10.88503885269165
[2024-12-07 20:45:07] [32mIntermediate result: 0.3674079  (Index 19)[0m
Epoch: 20, Steps: 65 | Train Loss: 0.4958298 Vali Loss: 0.2747181 Test Loss: 0.3674079
EarlyStopping counter: 2 out of 8
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 11.286622524261475
[2024-12-07 20:45:22] [32mIntermediate result: 0.36778495  (Index 20)[0m
Epoch: 21, Steps: 65 | Train Loss: 0.4943567 Vali Loss: 0.2741528 Test Loss: 0.3677849
Validation loss decreased (0.274347 --> 0.274153).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 10.784822225570679
[2024-12-07 20:45:37] [32mIntermediate result: 0.36750412  (Index 21)[0m
Epoch: 22, Steps: 65 | Train Loss: 0.4946509 Vali Loss: 0.2739681 Test Loss: 0.3675041
Validation loss decreased (0.274153 --> 0.273968).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 10.572110414505005
[2024-12-07 20:45:51] [32mIntermediate result: 0.36875254  (Index 22)[0m
Epoch: 23, Steps: 65 | Train Loss: 0.4945365 Vali Loss: 0.2750719 Test Loss: 0.3687525
EarlyStopping counter: 1 out of 8
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 10.472890853881836
[2024-12-07 20:46:05] [32mIntermediate result: 0.3680978  (Index 23)[0m
Epoch: 24, Steps: 65 | Train Loss: 0.4929391 Vali Loss: 0.2744015 Test Loss: 0.3680978
EarlyStopping counter: 2 out of 8
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 10.450401544570923
[2024-12-07 20:46:19] [32mIntermediate result: 0.3686472  (Index 24)[0m
Epoch: 25, Steps: 65 | Train Loss: 0.4923593 Vali Loss: 0.2749150 Test Loss: 0.3686472
EarlyStopping counter: 3 out of 8
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 10.497961282730103
[2024-12-07 20:46:34] [32mIntermediate result: 0.36730438  (Index 25)[0m
Epoch: 26, Steps: 65 | Train Loss: 0.4929581 Vali Loss: 0.2740749 Test Loss: 0.3673044
EarlyStopping counter: 4 out of 8
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 10.416566610336304
[2024-12-07 20:46:47] [32mIntermediate result: 0.36759484  (Index 26)[0m
Epoch: 27, Steps: 65 | Train Loss: 0.4919660 Vali Loss: 0.2738606 Test Loss: 0.3675948
Validation loss decreased (0.273968 --> 0.273861).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 10.440587520599365
[2024-12-07 20:47:02] [32mIntermediate result: 0.3672652  (Index 27)[0m
Epoch: 28, Steps: 65 | Train Loss: 0.4898829 Vali Loss: 0.2736580 Test Loss: 0.3672652
Validation loss decreased (0.273861 --> 0.273658).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 10.544128656387329
[2024-12-07 20:47:16] [32mIntermediate result: 0.36917824  (Index 28)[0m
Epoch: 29, Steps: 65 | Train Loss: 0.4886932 Vali Loss: 0.2745912 Test Loss: 0.3691782
EarlyStopping counter: 1 out of 8
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 10.538921117782593
[2024-12-07 20:47:30] [32mIntermediate result: 0.3685693  (Index 29)[0m
Epoch: 30, Steps: 65 | Train Loss: 0.4889600 Vali Loss: 0.2747135 Test Loss: 0.3685693
EarlyStopping counter: 2 out of 8
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 10.385295391082764
[2024-12-07 20:47:44] [32mIntermediate result: 0.36863083  (Index 30)[0m
Epoch: 31, Steps: 65 | Train Loss: 0.4864209 Vali Loss: 0.2748065 Test Loss: 0.3686308
EarlyStopping counter: 3 out of 8
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 10.633341312408447
[2024-12-07 20:47:58] [32mIntermediate result: 0.36755374  (Index 31)[0m
Epoch: 32, Steps: 65 | Train Loss: 0.4893240 Vali Loss: 0.2733913 Test Loss: 0.3675537
Validation loss decreased (0.273658 --> 0.273391).  Saving model ...
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 10.460111141204834
[2024-12-07 20:48:13] [32mIntermediate result: 0.3680272  (Index 32)[0m
Epoch: 33, Steps: 65 | Train Loss: 0.4863940 Vali Loss: 0.2741445 Test Loss: 0.3680272
EarlyStopping counter: 1 out of 8
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 10.507876873016357
[2024-12-07 20:48:27] [32mIntermediate result: 0.36753386  (Index 33)[0m
Epoch: 34, Steps: 65 | Train Loss: 0.4868545 Vali Loss: 0.2732259 Test Loss: 0.3675339
Validation loss decreased (0.273391 --> 0.273226).  Saving model ...
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 10.566632986068726
[2024-12-07 20:48:41] [32mIntermediate result: 0.36840445  (Index 34)[0m
Epoch: 35, Steps: 65 | Train Loss: 0.4879481 Vali Loss: 0.2741167 Test Loss: 0.3684044
EarlyStopping counter: 1 out of 8
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 10.982161521911621
[2024-12-07 20:48:56] [32mIntermediate result: 0.36971936  (Index 35)[0m
Epoch: 36, Steps: 65 | Train Loss: 0.4863898 Vali Loss: 0.2751852 Test Loss: 0.3697194
EarlyStopping counter: 2 out of 8
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 10.730129718780518
[2024-12-07 20:49:10] [32mIntermediate result: 0.36800122  (Index 36)[0m
Epoch: 37, Steps: 65 | Train Loss: 0.4878107 Vali Loss: 0.2735047 Test Loss: 0.3680012
EarlyStopping counter: 3 out of 8
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 10.52416706085205
[2024-12-07 20:49:25] [32mIntermediate result: 0.36857724  (Index 37)[0m
Epoch: 38, Steps: 65 | Train Loss: 0.4850591 Vali Loss: 0.2747917 Test Loss: 0.3685772
EarlyStopping counter: 4 out of 8
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 10.559629201889038
[2024-12-07 20:49:39] [32mIntermediate result: 0.3681478  (Index 38)[0m
Epoch: 39, Steps: 65 | Train Loss: 0.4881983 Vali Loss: 0.2741034 Test Loss: 0.3681478
EarlyStopping counter: 5 out of 8
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 10.646708488464355
[2024-12-07 20:49:53] [32mIntermediate result: 0.36828902  (Index 39)[0m
Epoch: 40, Steps: 65 | Train Loss: 0.4884370 Vali Loss: 0.2740140 Test Loss: 0.3682890
EarlyStopping counter: 6 out of 8
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 10.445699214935303
[2024-12-07 20:50:07] [32mIntermediate result: 0.36765194  (Index 40)[0m
Epoch: 41, Steps: 65 | Train Loss: 0.4874610 Vali Loss: 0.2736316 Test Loss: 0.3676519
EarlyStopping counter: 7 out of 8
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 10.601560592651367
[2024-12-07 20:50:22] [32mIntermediate result: 0.36790094  (Index 41)[0m
Epoch: 42, Steps: 65 | Train Loss: 0.4867361 Vali Loss: 0.2737316 Test Loss: 0.3679009
EarlyStopping counter: 8 out of 8
Early stopping
>>>>>>>testing : 24_2_2_96_192_MGSformer_TST_ETTh2_ftM_sl96_ll18_pl192_dm20_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3675338923931122, mae:0.38545355200767517, rse:0.4861275553703308
[2024-12-07 20:50:25] [32mFinal result: 0.3675339[0m
