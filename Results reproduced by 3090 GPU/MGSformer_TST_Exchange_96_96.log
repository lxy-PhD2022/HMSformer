Args in experiment:
Namespace(accumulation_steps=2, activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', compress_len=3, d_ff=128, d_layers=1, d_model=16, data='custom', data_path='exchange_rate.csv', dec_in=7, decomposition=0, des='Exp', device_ids=[0, 1, 2], devices='0,1,2', distil=True, do_predict=False, dropout=0.3, dvices='0,1,2', e_layers=1, embed='timeF', embed_type=0, enc_in=8, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='type3', model='MGSformer_TST', model_id='Exchange_96_96', momentum=0.8, moving_avg=25, n=6, n_heads=1, n_intra=12, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=8, pct_start=0.3, period=13, pred_len=96, random_seed=2021, revin=1, root_path='./dataset/', seq_len=96, stride=8, subtract_last=0, target='OT', test_flop=False, traffic=0, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=True, x=5)
Use GPU: cuda:0
>>>>>>>start training : 13_12_6_Exchange_96_96_MGSformer_TST_custom_ftM_sl96_ll18_pl96_dm5_nh1_el1_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
module.model.backbone.W_pos_intra: 40
module.model.backbone.W_pos: 65
module.model.backbone.W_pos_coarse: 40
module.model.backbone.W_P_intra.weight: 65
module.model.backbone.W_P_intra.bias: 5
module.model.backbone.W_P.weight: 15
module.model.backbone.W_P.bias: 5
module.model.backbone.W_P_coarse.weight: 120
module.model.backbone.W_P_coarse.bias: 5
module.model.backbone.encoder.layers.0.self_attn.W_Q.weight: 25
module.model.backbone.encoder.layers.0.self_attn.W_Q.bias: 5
module.model.backbone.encoder.layers.0.self_attn.W_K.weight: 25
module.model.backbone.encoder.layers.0.self_attn.W_K.bias: 5
module.model.backbone.encoder.layers.0.self_attn.W_V.weight: 25
module.model.backbone.encoder.layers.0.self_attn.W_V.bias: 5
module.model.backbone.encoder.layers.0.self_attn.to_out.0.weight: 25
module.model.backbone.encoder.layers.0.self_attn.to_out.0.bias: 5
module.model.backbone.encoder.layers.0.norm_attn.1.weight: 5
module.model.backbone.encoder.layers.0.norm_attn.1.bias: 5
module.model.backbone.encoder.layers.0.ff.0.weight: 640
module.model.backbone.encoder.layers.0.ff.0.bias: 128
module.model.backbone.encoder.layers.0.ff.3.weight: 640
module.model.backbone.encoder.layers.0.ff.3.bias: 5
module.model.backbone.encoder.layers.0.norm_ffn.1.weight: 5
module.model.backbone.encoder.layers.0.norm_ffn.1.bias: 5
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.weight: 25
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.bias: 5
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.weight: 25
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.bias: 5
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.weight: 25
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.bias: 5
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.weight: 25
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.bias: 5
module.model.backbone.encoder_intra.layers.0.norm_attn.1.weight: 5
module.model.backbone.encoder_intra.layers.0.norm_attn.1.bias: 5
module.model.backbone.encoder_intra.layers.0.ff.0.weight: 640
module.model.backbone.encoder_intra.layers.0.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.0.ff.3.weight: 640
module.model.backbone.encoder_intra.layers.0.ff.3.bias: 5
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.weight: 5
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.bias: 5
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.weight: 25
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.bias: 5
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.weight: 25
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.bias: 5
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.weight: 25
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.bias: 5
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.weight: 25
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.bias: 5
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.weight: 5
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.bias: 5
module.model.backbone.encoder_coarse.layers.0.ff.0.weight: 640
module.model.backbone.encoder_coarse.layers.0.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.0.ff.3.weight: 640
module.model.backbone.encoder_coarse.layers.0.ff.3.bias: 5
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.weight: 5
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.bias: 5
module.model.head.linear.weight: 54240
module.model.head.linear.bias: 96
module.model.compress.weight: 288
module.model.compress.bias: 3
Total trainable parameters: 59646
train 5120
val 665
test 1422
Epoch: 1 cost time: 4.389158010482788
[2024-12-08 00:20:40] [32mIntermediate result: 0.13936438  (Index 0)[0m
Epoch: 1, Steps: 40 | Train Loss: 0.2206089 Vali Loss: 0.1956997 Test Loss: 0.1393644
Validation loss decreased (inf --> 0.195700).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 3.0921833515167236
[2024-12-08 00:20:44] [32mIntermediate result: 0.10561877  (Index 1)[0m
Epoch: 2, Steps: 40 | Train Loss: 0.1938839 Vali Loss: 0.1622478 Test Loss: 0.1056188
Validation loss decreased (0.195700 --> 0.162248).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 3.073725700378418
[2024-12-08 00:20:48] [32mIntermediate result: 0.09345365  (Index 2)[0m
Epoch: 3, Steps: 40 | Train Loss: 0.1637456 Vali Loss: 0.1544579 Test Loss: 0.0934537
Validation loss decreased (0.162248 --> 0.154458).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 3.154928684234619
[2024-12-08 00:20:53] [32mIntermediate result: 0.08951717  (Index 3)[0m
Epoch: 4, Steps: 40 | Train Loss: 0.1528752 Vali Loss: 0.1499524 Test Loss: 0.0895172
Validation loss decreased (0.154458 --> 0.149952).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 3.3126273155212402
[2024-12-08 00:20:57] [32mIntermediate result: 0.08744611  (Index 4)[0m
Epoch: 5, Steps: 40 | Train Loss: 0.1468555 Vali Loss: 0.1461648 Test Loss: 0.0874461
Validation loss decreased (0.149952 --> 0.146165).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 3.1106438636779785
[2024-12-08 00:21:02] [32mIntermediate result: 0.086032785  (Index 5)[0m
Epoch: 6, Steps: 40 | Train Loss: 0.1433961 Vali Loss: 0.1427503 Test Loss: 0.0860328
Validation loss decreased (0.146165 --> 0.142750).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 3.085620880126953
[2024-12-08 00:21:06] [32mIntermediate result: 0.08494769  (Index 6)[0m
Epoch: 7, Steps: 40 | Train Loss: 0.1408769 Vali Loss: 0.1409637 Test Loss: 0.0849477
Validation loss decreased (0.142750 --> 0.140964).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 3.054215669631958
[2024-12-08 00:21:10] [32mIntermediate result: 0.08421558  (Index 7)[0m
Epoch: 8, Steps: 40 | Train Loss: 0.1389861 Vali Loss: 0.1383463 Test Loss: 0.0842156
Validation loss decreased (0.140964 --> 0.138346).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 3.286595106124878
[2024-12-08 00:21:15] [32mIntermediate result: 0.08354426  (Index 8)[0m
Epoch: 9, Steps: 40 | Train Loss: 0.1373909 Vali Loss: 0.1386298 Test Loss: 0.0835443
EarlyStopping counter: 1 out of 8
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 3.203187942504883
[2024-12-08 00:21:20] [32mIntermediate result: 0.083182685  (Index 9)[0m
Epoch: 10, Steps: 40 | Train Loss: 0.1362114 Vali Loss: 0.1376350 Test Loss: 0.0831827
Validation loss decreased (0.138346 --> 0.137635).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 3.3178000450134277
[2024-12-08 00:21:24] [32mIntermediate result: 0.08278839  (Index 10)[0m
Epoch: 11, Steps: 40 | Train Loss: 0.1349122 Vali Loss: 0.1369748 Test Loss: 0.0827884
Validation loss decreased (0.137635 --> 0.136975).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 3.2149128913879395
[2024-12-08 00:21:29] [32mIntermediate result: 0.082522035  (Index 11)[0m
Epoch: 12, Steps: 40 | Train Loss: 0.1342140 Vali Loss: 0.1371697 Test Loss: 0.0825220
EarlyStopping counter: 1 out of 8
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 3.274916410446167
[2024-12-08 00:21:34] [32mIntermediate result: 0.08228149  (Index 12)[0m
Epoch: 13, Steps: 40 | Train Loss: 0.1339655 Vali Loss: 0.1348809 Test Loss: 0.0822815
Validation loss decreased (0.136975 --> 0.134881).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 3.164149761199951
[2024-12-08 00:21:38] [32mIntermediate result: 0.08211947  (Index 13)[0m
Epoch: 14, Steps: 40 | Train Loss: 0.1331433 Vali Loss: 0.1341674 Test Loss: 0.0821195
Validation loss decreased (0.134881 --> 0.134167).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 3.2055749893188477
[2024-12-08 00:21:43] [32mIntermediate result: 0.08198135  (Index 14)[0m
Epoch: 15, Steps: 40 | Train Loss: 0.1326859 Vali Loss: 0.1333802 Test Loss: 0.0819814
Validation loss decreased (0.134167 --> 0.133380).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 3.1840670108795166
[2024-12-08 00:21:48] [32mIntermediate result: 0.0818626  (Index 15)[0m
Epoch: 16, Steps: 40 | Train Loss: 0.1322694 Vali Loss: 0.1327426 Test Loss: 0.0818626
Validation loss decreased (0.133380 --> 0.132743).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 3.1636533737182617
[2024-12-08 00:21:52] [32mIntermediate result: 0.08183515  (Index 16)[0m
Epoch: 17, Steps: 40 | Train Loss: 0.1319146 Vali Loss: 0.1344431 Test Loss: 0.0818352
EarlyStopping counter: 1 out of 8
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 3.0676991939544678
[2024-12-08 00:21:57] [32mIntermediate result: 0.081702024  (Index 17)[0m
Epoch: 18, Steps: 40 | Train Loss: 0.1318636 Vali Loss: 0.1326658 Test Loss: 0.0817020
Validation loss decreased (0.132743 --> 0.132666).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 3.272597074508667
[2024-12-08 00:22:01] [32mIntermediate result: 0.081706785  (Index 18)[0m
Epoch: 19, Steps: 40 | Train Loss: 0.1314565 Vali Loss: 0.1342523 Test Loss: 0.0817068
EarlyStopping counter: 1 out of 8
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 3.3504464626312256
[2024-12-08 00:22:06] [32mIntermediate result: 0.081570975  (Index 19)[0m
Epoch: 20, Steps: 40 | Train Loss: 0.1311446 Vali Loss: 0.1327513 Test Loss: 0.0815710
EarlyStopping counter: 2 out of 8
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 3.06866455078125
[2024-12-08 00:22:10] [32mIntermediate result: 0.08155212  (Index 20)[0m
Epoch: 21, Steps: 40 | Train Loss: 0.1313741 Vali Loss: 0.1330252 Test Loss: 0.0815521
EarlyStopping counter: 3 out of 8
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 3.0670816898345947
[2024-12-08 00:22:15] [32mIntermediate result: 0.0814988  (Index 21)[0m
Epoch: 22, Steps: 40 | Train Loss: 0.1306627 Vali Loss: 0.1323525 Test Loss: 0.0814988
Validation loss decreased (0.132666 --> 0.132352).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 3.3353259563446045
[2024-12-08 00:22:19] [32mIntermediate result: 0.081402905  (Index 22)[0m
Epoch: 23, Steps: 40 | Train Loss: 0.1307720 Vali Loss: 0.1336344 Test Loss: 0.0814029
EarlyStopping counter: 1 out of 8
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 3.1361522674560547
[2024-12-08 00:22:24] [32mIntermediate result: 0.08135953  (Index 23)[0m
Epoch: 24, Steps: 40 | Train Loss: 0.1304677 Vali Loss: 0.1319818 Test Loss: 0.0813595
Validation loss decreased (0.132352 --> 0.131982).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 2.8819384574890137
[2024-12-08 00:22:28] [32mIntermediate result: 0.081368595  (Index 24)[0m
Epoch: 25, Steps: 40 | Train Loss: 0.1304592 Vali Loss: 0.1323198 Test Loss: 0.0813686
EarlyStopping counter: 1 out of 8
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 3.0692803859710693
[2024-12-08 00:22:33] [32mIntermediate result: 0.081441596  (Index 25)[0m
Epoch: 26, Steps: 40 | Train Loss: 0.1302843 Vali Loss: 0.1327323 Test Loss: 0.0814416
EarlyStopping counter: 2 out of 8
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 3.4135708808898926
[2024-12-08 00:22:37] [32mIntermediate result: 0.08137377  (Index 26)[0m
Epoch: 27, Steps: 40 | Train Loss: 0.1303991 Vali Loss: 0.1329442 Test Loss: 0.0813738
EarlyStopping counter: 3 out of 8
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 3.218280792236328
[2024-12-08 00:22:42] [32mIntermediate result: 0.08132893  (Index 27)[0m
Epoch: 28, Steps: 40 | Train Loss: 0.1300373 Vali Loss: 0.1337545 Test Loss: 0.0813289
EarlyStopping counter: 4 out of 8
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 3.292628049850464
[2024-12-08 00:22:47] [32mIntermediate result: 0.081300326  (Index 28)[0m
Epoch: 29, Steps: 40 | Train Loss: 0.1301817 Vali Loss: 0.1316742 Test Loss: 0.0813003
Validation loss decreased (0.131982 --> 0.131674).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 3.0993857383728027
[2024-12-08 00:22:51] [32mIntermediate result: 0.081336446  (Index 29)[0m
Epoch: 30, Steps: 40 | Train Loss: 0.1297867 Vali Loss: 0.1318042 Test Loss: 0.0813364
EarlyStopping counter: 1 out of 8
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 3.3706161975860596
[2024-12-08 00:22:56] [32mIntermediate result: 0.08129013  (Index 30)[0m
Epoch: 31, Steps: 40 | Train Loss: 0.1300770 Vali Loss: 0.1330328 Test Loss: 0.0812901
EarlyStopping counter: 2 out of 8
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 3.084700345993042
[2024-12-08 00:23:00] [32mIntermediate result: 0.08128074  (Index 31)[0m
Epoch: 32, Steps: 40 | Train Loss: 0.1299348 Vali Loss: 0.1327787 Test Loss: 0.0812807
EarlyStopping counter: 3 out of 8
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 3.222327709197998
[2024-12-08 00:23:05] [32mIntermediate result: 0.08125077  (Index 32)[0m
Epoch: 33, Steps: 40 | Train Loss: 0.1297779 Vali Loss: 0.1315030 Test Loss: 0.0812508
Validation loss decreased (0.131674 --> 0.131503).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 3.2602875232696533
[2024-12-08 00:23:10] [32mIntermediate result: 0.08129041  (Index 33)[0m
Epoch: 34, Steps: 40 | Train Loss: 0.1298220 Vali Loss: 0.1315177 Test Loss: 0.0812904
EarlyStopping counter: 1 out of 8
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 3.310950517654419
[2024-12-08 00:23:14] [32mIntermediate result: 0.081252836  (Index 34)[0m
Epoch: 35, Steps: 40 | Train Loss: 0.1299189 Vali Loss: 0.1314481 Test Loss: 0.0812528
Validation loss decreased (0.131503 --> 0.131448).  Saving model ...
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 3.219431161880493
[2024-12-08 00:23:19] [32mIntermediate result: 0.08120751  (Index 35)[0m
Epoch: 36, Steps: 40 | Train Loss: 0.1296045 Vali Loss: 0.1324401 Test Loss: 0.0812075
EarlyStopping counter: 1 out of 8
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 3.426152229309082
[2024-12-08 00:23:24] [32mIntermediate result: 0.08126342  (Index 36)[0m
Epoch: 37, Steps: 40 | Train Loss: 0.1295112 Vali Loss: 0.1323555 Test Loss: 0.0812634
EarlyStopping counter: 2 out of 8
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 3.332731008529663
[2024-12-08 00:23:28] [32mIntermediate result: 0.08118203  (Index 37)[0m
Epoch: 38, Steps: 40 | Train Loss: 0.1293901 Vali Loss: 0.1337252 Test Loss: 0.0811820
EarlyStopping counter: 3 out of 8
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 2.9563379287719727
[2024-12-08 00:23:33] [32mIntermediate result: 0.08121875  (Index 38)[0m
Epoch: 39, Steps: 40 | Train Loss: 0.1296283 Vali Loss: 0.1316059 Test Loss: 0.0812187
EarlyStopping counter: 4 out of 8
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 3.2379658222198486
[2024-12-08 00:23:37] [32mIntermediate result: 0.081184335  (Index 39)[0m
Epoch: 40, Steps: 40 | Train Loss: 0.1298056 Vali Loss: 0.1320003 Test Loss: 0.0811843
EarlyStopping counter: 5 out of 8
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 3.1198079586029053
[2024-12-08 00:23:42] [32mIntermediate result: 0.08122274  (Index 40)[0m
Epoch: 41, Steps: 40 | Train Loss: 0.1294344 Vali Loss: 0.1322912 Test Loss: 0.0812227
EarlyStopping counter: 6 out of 8
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 3.208343267440796
[2024-12-08 00:23:46] [32mIntermediate result: 0.08117045  (Index 41)[0m
Epoch: 42, Steps: 40 | Train Loss: 0.1293914 Vali Loss: 0.1326863 Test Loss: 0.0811704
EarlyStopping counter: 7 out of 8
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 3.27490234375
[2024-12-08 00:23:51] [32mIntermediate result: 0.081156194  (Index 42)[0m
Epoch: 43, Steps: 40 | Train Loss: 0.1293404 Vali Loss: 0.1317141 Test Loss: 0.0811562
EarlyStopping counter: 8 out of 8
Early stopping
>>>>>>>testing : 13_12_6_Exchange_96_96_MGSformer_TST_custom_ftM_sl96_ll18_pl96_dm5_nh1_el1_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1422
mse:0.08125282824039459, mae:0.19936040043830872, rse:0.21710318326950073
[2024-12-08 00:23:52] [32mFinal result: 0.08125283[0m
