Args in experiment:
Namespace(accumulation_steps=2, activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', compress_len=10, d_ff=256, d_layers=1, d_model=128, data='ETTm2', data_path='ETTm2.csv', dec_in=7, decomposition=0, des='Exp', device_ids=[0, 1, 2], devices='0,1,2', distil=True, do_predict=False, dropout=0.2, dvices='0,1,2', e_layers=3, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.2, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='TST', model='MGSformer_TST', model_id='96_336', momentum=0.8, moving_avg=25, n=2, n_heads=16, n_intra=2, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=8, pct_start=0.4, period=24, pred_len=336, random_seed=2021, revin=1, root_path='./dataset/', seq_len=96, stride=8, subtract_last=0, target='OT', test_flop=False, traffic=0, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=True, x=5)
Use GPU: cuda:0
>>>>>>>start training : 24_2_2_96_336_MGSformer_TST_ETTm2_ftM_sl96_ll18_pl336_dm80_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
module.model.backbone.W_pos_intra: 320
module.model.backbone.W_pos: 1920
module.model.backbone.W_pos_coarse: 560
module.model.backbone.W_P_intra.weight: 3840
module.model.backbone.W_P_intra.bias: 80
module.model.backbone.W_P.weight: 960
module.model.backbone.W_P.bias: 80
module.model.backbone.W_P_coarse.weight: 5600
module.model.backbone.W_P_coarse.bias: 80
module.model.backbone.encoder.layers.0.self_attn.W_Q.weight: 6400
module.model.backbone.encoder.layers.0.self_attn.W_Q.bias: 80
module.model.backbone.encoder.layers.0.self_attn.W_K.weight: 6400
module.model.backbone.encoder.layers.0.self_attn.W_K.bias: 80
module.model.backbone.encoder.layers.0.self_attn.W_V.weight: 6400
module.model.backbone.encoder.layers.0.self_attn.W_V.bias: 80
module.model.backbone.encoder.layers.0.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder.layers.0.self_attn.to_out.0.bias: 80
module.model.backbone.encoder.layers.0.norm_attn.1.weight: 80
module.model.backbone.encoder.layers.0.norm_attn.1.bias: 80
module.model.backbone.encoder.layers.0.ff.0.weight: 20480
module.model.backbone.encoder.layers.0.ff.0.bias: 256
module.model.backbone.encoder.layers.0.ff.3.weight: 20480
module.model.backbone.encoder.layers.0.ff.3.bias: 80
module.model.backbone.encoder.layers.0.norm_ffn.1.weight: 80
module.model.backbone.encoder.layers.0.norm_ffn.1.bias: 80
module.model.backbone.encoder.layers.1.self_attn.W_Q.weight: 6400
module.model.backbone.encoder.layers.1.self_attn.W_Q.bias: 80
module.model.backbone.encoder.layers.1.self_attn.W_K.weight: 6400
module.model.backbone.encoder.layers.1.self_attn.W_K.bias: 80
module.model.backbone.encoder.layers.1.self_attn.W_V.weight: 6400
module.model.backbone.encoder.layers.1.self_attn.W_V.bias: 80
module.model.backbone.encoder.layers.1.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder.layers.1.self_attn.to_out.0.bias: 80
module.model.backbone.encoder.layers.1.norm_attn.1.weight: 80
module.model.backbone.encoder.layers.1.norm_attn.1.bias: 80
module.model.backbone.encoder.layers.1.ff.0.weight: 20480
module.model.backbone.encoder.layers.1.ff.0.bias: 256
module.model.backbone.encoder.layers.1.ff.3.weight: 20480
module.model.backbone.encoder.layers.1.ff.3.bias: 80
module.model.backbone.encoder.layers.1.norm_ffn.1.weight: 80
module.model.backbone.encoder.layers.1.norm_ffn.1.bias: 80
module.model.backbone.encoder.layers.2.self_attn.W_Q.weight: 6400
module.model.backbone.encoder.layers.2.self_attn.W_Q.bias: 80
module.model.backbone.encoder.layers.2.self_attn.W_K.weight: 6400
module.model.backbone.encoder.layers.2.self_attn.W_K.bias: 80
module.model.backbone.encoder.layers.2.self_attn.W_V.weight: 6400
module.model.backbone.encoder.layers.2.self_attn.W_V.bias: 80
module.model.backbone.encoder.layers.2.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder.layers.2.self_attn.to_out.0.bias: 80
module.model.backbone.encoder.layers.2.norm_attn.1.weight: 80
module.model.backbone.encoder.layers.2.norm_attn.1.bias: 80
module.model.backbone.encoder.layers.2.ff.0.weight: 20480
module.model.backbone.encoder.layers.2.ff.0.bias: 256
module.model.backbone.encoder.layers.2.ff.3.weight: 20480
module.model.backbone.encoder.layers.2.ff.3.bias: 80
module.model.backbone.encoder.layers.2.norm_ffn.1.weight: 80
module.model.backbone.encoder.layers.2.norm_ffn.1.bias: 80
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.weight: 6400
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.bias: 80
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.weight: 6400
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.bias: 80
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.weight: 6400
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.bias: 80
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.bias: 80
module.model.backbone.encoder_intra.layers.0.norm_attn.1.weight: 80
module.model.backbone.encoder_intra.layers.0.norm_attn.1.bias: 80
module.model.backbone.encoder_intra.layers.0.ff.0.weight: 20480
module.model.backbone.encoder_intra.layers.0.ff.0.bias: 256
module.model.backbone.encoder_intra.layers.0.ff.3.weight: 20480
module.model.backbone.encoder_intra.layers.0.ff.3.bias: 80
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.weight: 80
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.bias: 80
module.model.backbone.encoder_intra.layers.1.self_attn.W_Q.weight: 6400
module.model.backbone.encoder_intra.layers.1.self_attn.W_Q.bias: 80
module.model.backbone.encoder_intra.layers.1.self_attn.W_K.weight: 6400
module.model.backbone.encoder_intra.layers.1.self_attn.W_K.bias: 80
module.model.backbone.encoder_intra.layers.1.self_attn.W_V.weight: 6400
module.model.backbone.encoder_intra.layers.1.self_attn.W_V.bias: 80
module.model.backbone.encoder_intra.layers.1.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder_intra.layers.1.self_attn.to_out.0.bias: 80
module.model.backbone.encoder_intra.layers.1.norm_attn.1.weight: 80
module.model.backbone.encoder_intra.layers.1.norm_attn.1.bias: 80
module.model.backbone.encoder_intra.layers.1.ff.0.weight: 20480
module.model.backbone.encoder_intra.layers.1.ff.0.bias: 256
module.model.backbone.encoder_intra.layers.1.ff.3.weight: 20480
module.model.backbone.encoder_intra.layers.1.ff.3.bias: 80
module.model.backbone.encoder_intra.layers.1.norm_ffn.1.weight: 80
module.model.backbone.encoder_intra.layers.1.norm_ffn.1.bias: 80
module.model.backbone.encoder_intra.layers.2.self_attn.W_Q.weight: 6400
module.model.backbone.encoder_intra.layers.2.self_attn.W_Q.bias: 80
module.model.backbone.encoder_intra.layers.2.self_attn.W_K.weight: 6400
module.model.backbone.encoder_intra.layers.2.self_attn.W_K.bias: 80
module.model.backbone.encoder_intra.layers.2.self_attn.W_V.weight: 6400
module.model.backbone.encoder_intra.layers.2.self_attn.W_V.bias: 80
module.model.backbone.encoder_intra.layers.2.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder_intra.layers.2.self_attn.to_out.0.bias: 80
module.model.backbone.encoder_intra.layers.2.norm_attn.1.weight: 80
module.model.backbone.encoder_intra.layers.2.norm_attn.1.bias: 80
module.model.backbone.encoder_intra.layers.2.ff.0.weight: 20480
module.model.backbone.encoder_intra.layers.2.ff.0.bias: 256
module.model.backbone.encoder_intra.layers.2.ff.3.weight: 20480
module.model.backbone.encoder_intra.layers.2.ff.3.bias: 80
module.model.backbone.encoder_intra.layers.2.norm_ffn.1.weight: 80
module.model.backbone.encoder_intra.layers.2.norm_ffn.1.bias: 80
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.weight: 6400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.bias: 80
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.weight: 6400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.bias: 80
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.weight: 6400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.bias: 80
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.bias: 80
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.weight: 80
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.bias: 80
module.model.backbone.encoder_coarse.layers.0.ff.0.weight: 20480
module.model.backbone.encoder_coarse.layers.0.ff.0.bias: 256
module.model.backbone.encoder_coarse.layers.0.ff.3.weight: 20480
module.model.backbone.encoder_coarse.layers.0.ff.3.bias: 80
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.weight: 80
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.bias: 80
module.model.backbone.encoder_coarse.layers.1.self_attn.W_Q.weight: 6400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_Q.bias: 80
module.model.backbone.encoder_coarse.layers.1.self_attn.W_K.weight: 6400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_K.bias: 80
module.model.backbone.encoder_coarse.layers.1.self_attn.W_V.weight: 6400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_V.bias: 80
module.model.backbone.encoder_coarse.layers.1.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder_coarse.layers.1.self_attn.to_out.0.bias: 80
module.model.backbone.encoder_coarse.layers.1.norm_attn.1.weight: 80
module.model.backbone.encoder_coarse.layers.1.norm_attn.1.bias: 80
module.model.backbone.encoder_coarse.layers.1.ff.0.weight: 20480
module.model.backbone.encoder_coarse.layers.1.ff.0.bias: 256
module.model.backbone.encoder_coarse.layers.1.ff.3.weight: 20480
module.model.backbone.encoder_coarse.layers.1.ff.3.bias: 80
module.model.backbone.encoder_coarse.layers.1.norm_ffn.1.weight: 80
module.model.backbone.encoder_coarse.layers.1.norm_ffn.1.bias: 80
module.model.backbone.encoder_coarse.layers.2.self_attn.W_Q.weight: 6400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_Q.bias: 80
module.model.backbone.encoder_coarse.layers.2.self_attn.W_K.weight: 6400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_K.bias: 80
module.model.backbone.encoder_coarse.layers.2.self_attn.W_V.weight: 6400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_V.bias: 80
module.model.backbone.encoder_coarse.layers.2.self_attn.to_out.0.weight: 6400
module.model.backbone.encoder_coarse.layers.2.self_attn.to_out.0.bias: 80
module.model.backbone.encoder_coarse.layers.2.norm_attn.1.weight: 80
module.model.backbone.encoder_coarse.layers.2.norm_attn.1.bias: 80
module.model.backbone.encoder_coarse.layers.2.ff.0.weight: 20480
module.model.backbone.encoder_coarse.layers.2.ff.0.bias: 256
module.model.backbone.encoder_coarse.layers.2.ff.3.weight: 20480
module.model.backbone.encoder_coarse.layers.2.ff.3.bias: 80
module.model.backbone.encoder_coarse.layers.2.norm_ffn.1.weight: 80
module.model.backbone.encoder_coarse.layers.2.norm_ffn.1.bias: 80
module.model.head.linear.weight: 2714880
module.model.head.linear.bias: 336
module.model.compress.weight: 960
module.model.compress.bias: 10
Total trainable parameters: 3337450
train 34129
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.4704459
	speed: 0.1697s/iter; left time: 4498.1315s
	iters: 200, epoch: 1 | loss: 0.3351227
	speed: 0.1457s/iter; left time: 3847.7498s
Epoch: 1 cost time: 41.08834624290466
[2024-12-07 23:31:01] [32mIntermediate result: 0.31858405  (Index 0)[0m
Epoch: 1, Steps: 266 | Train Loss: 0.4823059 Vali Loss: 0.2269445 Test Loss: 0.3185841
Validation loss decreased (inf --> 0.226944).  Saving model ...
Updating learning rate to 4.147995783958166e-06
	iters: 100, epoch: 2 | loss: 0.5262541
	speed: 0.3780s/iter; left time: 9915.5285s
	iters: 200, epoch: 2 | loss: 0.5530431
	speed: 0.1514s/iter; left time: 3956.0265s
Epoch: 2 cost time: 40.30840516090393
[2024-12-07 23:31:54] [32mIntermediate result: 0.31367242  (Index 1)[0m
Epoch: 2, Steps: 266 | Train Loss: 0.4632204 Vali Loss: 0.2230738 Test Loss: 0.3136724
Validation loss decreased (0.226944 --> 0.223074).  Saving model ...
Updating learning rate to 4.591070521163098e-06
	iters: 100, epoch: 3 | loss: 0.4621954
	speed: 0.3702s/iter; left time: 9614.1409s
	iters: 200, epoch: 3 | loss: 0.3151023
	speed: 0.1530s/iter; left time: 3957.1149s
Epoch: 3 cost time: 40.28232789039612
[2024-12-07 23:32:47] [32mIntermediate result: 0.3110821  (Index 2)[0m
Epoch: 3, Steps: 266 | Train Loss: 0.4567891 Vali Loss: 0.2212737 Test Loss: 0.3110821
Validation loss decreased (0.223074 --> 0.221274).  Saving model ...
Updating learning rate to 5.326491995236255e-06
	iters: 100, epoch: 4 | loss: 0.2879832
	speed: 0.3800s/iter; left time: 9768.2896s
	iters: 200, epoch: 4 | loss: 0.8552508
	speed: 0.1491s/iter; left time: 3817.5195s
Epoch: 4 cost time: 39.88566493988037
[2024-12-07 23:33:40] [32mIntermediate result: 0.31046036  (Index 3)[0m
Epoch: 4, Steps: 266 | Train Loss: 0.4512470 Vali Loss: 0.2220543 Test Loss: 0.3104604
EarlyStopping counter: 1 out of 8
Updating learning rate to 6.349725236277868e-06
	iters: 100, epoch: 5 | loss: 0.3851655
	speed: 0.3856s/iter; left time: 9807.6075s
	iters: 200, epoch: 5 | loss: 0.3971292
	speed: 0.1553s/iter; left time: 3934.8385s
Epoch: 5 cost time: 41.15780806541443
[2024-12-07 23:34:35] [32mIntermediate result: 0.30760878  (Index 4)[0m
Epoch: 5, Steps: 266 | Train Loss: 0.4469186 Vali Loss: 0.2194098 Test Loss: 0.3076088
Validation loss decreased (0.221274 --> 0.219410).  Saving model ...
Updating learning rate to 7.654460485717921e-06
	iters: 100, epoch: 6 | loss: 0.4860181
	speed: 0.3921s/iter; left time: 9870.1419s
	iters: 200, epoch: 6 | loss: 0.6128907
	speed: 0.1532s/iter; left time: 3841.8978s
Epoch: 6 cost time: 40.71909785270691
[2024-12-07 23:35:29] [32mIntermediate result: 0.30625463  (Index 5)[0m
Epoch: 6, Steps: 266 | Train Loss: 0.4423638 Vali Loss: 0.2189001 Test Loss: 0.3062546
Validation loss decreased (0.219410 --> 0.218900).  Saving model ...
Updating learning rate to 9.232652105385623e-06
	iters: 100, epoch: 7 | loss: 0.5225165
	speed: 0.3887s/iter; left time: 9680.7309s
	iters: 200, epoch: 7 | loss: 0.4657205
	speed: 0.1537s/iter; left time: 3813.5066s
Epoch: 7 cost time: 40.94162631034851
[2024-12-07 23:36:24] [32mIntermediate result: 0.30509418  (Index 6)[0m
Epoch: 7, Steps: 266 | Train Loss: 0.4368405 Vali Loss: 0.2187819 Test Loss: 0.3050942
Validation loss decreased (0.218900 --> 0.218782).  Saving model ...
Updating learning rate to 1.1074568190864783e-05
	iters: 100, epoch: 8 | loss: 0.4044042
	speed: 0.3941s/iter; left time: 9709.9106s
	iters: 200, epoch: 8 | loss: 0.3134978
	speed: 0.1478s/iter; left time: 3626.3957s
Epoch: 8 cost time: 40.683367013931274
[2024-12-07 23:37:18] [32mIntermediate result: 0.30220166  (Index 7)[0m
Epoch: 8, Steps: 266 | Train Loss: 0.4307643 Vali Loss: 0.2181530 Test Loss: 0.3022017
Validation loss decreased (0.218782 --> 0.218153).  Saving model ...
Updating learning rate to 1.316885058319476e-05
	iters: 100, epoch: 9 | loss: 0.5029640
	speed: 0.3869s/iter; left time: 9429.3250s
	iters: 200, epoch: 9 | loss: 0.3322769
	speed: 0.1495s/iter; left time: 3629.7413s
Epoch: 9 cost time: 40.15823245048523
[2024-12-07 23:38:10] [32mIntermediate result: 0.30358964  (Index 8)[0m
Epoch: 9, Steps: 266 | Train Loss: 0.4227270 Vali Loss: 0.2196220 Test Loss: 0.3035896
EarlyStopping counter: 1 out of 8
Updating learning rate to 1.5502584908855415e-05
	iters: 100, epoch: 10 | loss: 0.4804745
	speed: 0.3755s/iter; left time: 9052.1516s
	iters: 200, epoch: 10 | loss: 0.3316757
	speed: 0.1513s/iter; left time: 3633.2893s
Epoch: 10 cost time: 40.76131534576416
[2024-12-07 23:39:05] [32mIntermediate result: 0.30276474  (Index 9)[0m
Epoch: 10, Steps: 266 | Train Loss: 0.4170982 Vali Loss: 0.2186752 Test Loss: 0.3027647
EarlyStopping counter: 2 out of 8
Updating learning rate to 1.806138021613527e-05
	iters: 100, epoch: 11 | loss: 0.5343047
	speed: 0.3968s/iter; left time: 9460.2164s
	iters: 200, epoch: 11 | loss: 0.4254145
	speed: 0.1490s/iter; left time: 3537.1286s
Epoch: 11 cost time: 40.02744817733765
[2024-12-07 23:39:58] [32mIntermediate result: 0.30163744  (Index 10)[0m
Epoch: 11, Steps: 266 | Train Loss: 0.4097132 Vali Loss: 0.2173417 Test Loss: 0.3016374
Validation loss decreased (0.218153 --> 0.217342).  Saving model ...
Updating learning rate to 2.0829457716805565e-05
	iters: 100, epoch: 12 | loss: 0.3750680
	speed: 0.3826s/iter; left time: 9019.6490s
	iters: 200, epoch: 12 | loss: 0.5168018
	speed: 0.1521s/iter; left time: 3569.6997s
Epoch: 12 cost time: 40.964131116867065
[2024-12-07 23:40:51] [32mIntermediate result: 0.2999508  (Index 11)[0m
Epoch: 12, Steps: 266 | Train Loss: 0.4024093 Vali Loss: 0.2162191 Test Loss: 0.2999508
Validation loss decreased (0.217342 --> 0.216219).  Saving model ...
Updating learning rate to 2.3789748085875986e-05
	iters: 100, epoch: 13 | loss: 0.3563004
	speed: 0.3858s/iter; left time: 8991.4921s
	iters: 200, epoch: 13 | loss: 0.4303656
	speed: 0.1493s/iter; left time: 3464.9428s
Epoch: 13 cost time: 40.66629242897034
[2024-12-07 23:41:45] [32mIntermediate result: 0.29933727  (Index 12)[0m
Epoch: 13, Steps: 266 | Train Loss: 0.3957511 Vali Loss: 0.2156114 Test Loss: 0.2993373
Validation loss decreased (0.216219 --> 0.215611).  Saving model ...
Updating learning rate to 2.6923996719433387e-05
	iters: 100, epoch: 14 | loss: 0.3454673
	speed: 0.3814s/iter; left time: 8787.9295s
	iters: 200, epoch: 14 | loss: 0.2246705
	speed: 0.1527s/iter; left time: 3503.9142s
Epoch: 14 cost time: 40.70499873161316
[2024-12-07 23:42:39] [32mIntermediate result: 0.30020818  (Index 13)[0m
Epoch: 14, Steps: 266 | Train Loss: 0.3889134 Vali Loss: 0.2173343 Test Loss: 0.3002082
EarlyStopping counter: 1 out of 8
Updating learning rate to 3.021287630149266e-05
	iters: 100, epoch: 15 | loss: 0.3678440
	speed: 0.3935s/iter; left time: 8961.9078s
	iters: 200, epoch: 15 | loss: 0.2836904
	speed: 0.1543s/iter; left time: 3499.8890s
Epoch: 15 cost time: 41.598175048828125
[2024-12-07 23:43:33] [32mIntermediate result: 0.29965723  (Index 14)[0m
Epoch: 15, Steps: 266 | Train Loss: 0.3820733 Vali Loss: 0.2169070 Test Loss: 0.2996572
EarlyStopping counter: 2 out of 8
Updating learning rate to 3.363610598571669e-05
	iters: 100, epoch: 16 | loss: 0.3604373
	speed: 0.3826s/iter; left time: 8611.7340s
	iters: 200, epoch: 16 | loss: 0.2742771
	speed: 0.1547s/iter; left time: 3466.1182s
Epoch: 16 cost time: 41.31802678108215
[2024-12-07 23:44:27] [32mIntermediate result: 0.30009484  (Index 15)[0m
Epoch: 16, Steps: 266 | Train Loss: 0.3786971 Vali Loss: 0.2166893 Test Loss: 0.3000948
EarlyStopping counter: 3 out of 8
Updating learning rate to 3.717257645707274e-05
	iters: 100, epoch: 17 | loss: 0.3409978
	speed: 0.3819s/iter; left time: 8495.8546s
	iters: 200, epoch: 17 | loss: 0.3416129
	speed: 0.1562s/iter; left time: 3458.8658s
Epoch: 17 cost time: 40.84967613220215
[2024-12-07 23:45:21] [32mIntermediate result: 0.3005724  (Index 16)[0m
Epoch: 17, Steps: 266 | Train Loss: 0.3742627 Vali Loss: 0.2182552 Test Loss: 0.3005724
EarlyStopping counter: 4 out of 8
Updating learning rate to 4.08004801022336e-05
	iters: 100, epoch: 18 | loss: 0.4657787
	speed: 0.3927s/iter; left time: 8630.5245s
	iters: 200, epoch: 18 | loss: 0.4073105
	speed: 0.1488s/iter; left time: 3254.7036s
Epoch: 18 cost time: 40.870301961898804
[2024-12-07 23:46:16] [32mIntermediate result: 0.2997888  (Index 17)[0m
Epoch: 18, Steps: 266 | Train Loss: 0.3710306 Vali Loss: 0.2168520 Test Loss: 0.2997888
EarlyStopping counter: 5 out of 8
Updating learning rate to 4.4497445486028815e-05
	iters: 100, epoch: 19 | loss: 0.3340511
	speed: 0.3882s/iter; left time: 8428.8275s
	iters: 200, epoch: 19 | loss: 0.3510688
	speed: 0.1489s/iter; left time: 3218.8444s
Epoch: 19 cost time: 39.76082229614258
[2024-12-07 23:47:08] [32mIntermediate result: 0.3000511  (Index 18)[0m
Epoch: 19, Steps: 266 | Train Loss: 0.3655592 Vali Loss: 0.2183071 Test Loss: 0.3000511
EarlyStopping counter: 6 out of 8
Updating learning rate to 4.8240675304698384e-05
	iters: 100, epoch: 20 | loss: 0.4769010
	speed: 0.3798s/iter; left time: 8146.4256s
	iters: 200, epoch: 20 | loss: 0.3621797
	speed: 0.1505s/iter; left time: 3213.2981s
Epoch: 20 cost time: 40.45492720603943
[2024-12-07 23:48:02] [32mIntermediate result: 0.30165264  (Index 19)[0m
Epoch: 20, Steps: 266 | Train Loss: 0.3614744 Vali Loss: 0.2189561 Test Loss: 0.3016526
EarlyStopping counter: 7 out of 8
Updating learning rate to 5.2007086965261054e-05
	iters: 100, epoch: 21 | loss: 0.4132157
	speed: 0.3865s/iter; left time: 8185.8997s
	iters: 200, epoch: 21 | loss: 0.3167951
	speed: 0.1526s/iter; left time: 3217.6052s
Epoch: 21 cost time: 40.50473093986511
[2024-12-07 23:48:56] [32mIntermediate result: 0.3043238  (Index 20)[0m
Epoch: 21, Steps: 266 | Train Loss: 0.3573539 Vali Loss: 0.2210732 Test Loss: 0.3043238
EarlyStopping counter: 8 out of 8
Early stopping
>>>>>>>testing : 24_2_2_96_336_MGSformer_TST_ETTm2_ftM_sl96_ll18_pl336_dm80_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:0.29933735728263855, mae:0.34131717681884766, rse:0.44141238927841187
[2024-12-07 23:49:05] [32mFinal result: 0.29933736[0m
