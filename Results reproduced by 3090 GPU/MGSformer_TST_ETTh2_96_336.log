Args in experiment:
Namespace(accumulation_steps=2, activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', compress_len=10, d_ff=128, d_layers=1, d_model=16, data='ETTh2', data_path='ETTh2.csv', dec_in=7, decomposition=0, des='Exp', device_ids=[0, 1, 2], devices='0,1,2', distil=True, do_predict=False, dropout=0.3, dvices='0,1,2', e_layers=3, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=18, learning_rate=0.0001, loss='mse', lradj='type3', model='MGSformer_TST', model_id='96_336', momentum=0.8, moving_avg=25, n=2, n_heads=4, n_intra=2, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=8, pct_start=0.3, period=24, pred_len=336, random_seed=2021, revin=1, root_path='./dataset/', seq_len=96, stride=8, subtract_last=0, target='OT', test_flop=False, traffic=0, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=True, x=5)
Use GPU: cuda:0
>>>>>>>start training : 24_2_2_96_336_MGSformer_TST_ETTh2_ftM_sl96_ll18_pl336_dm20_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
module.model.backbone.W_pos_intra: 80
module.model.backbone.W_pos: 480
module.model.backbone.W_pos_coarse: 140
module.model.backbone.W_P_intra.weight: 960
module.model.backbone.W_P_intra.bias: 20
module.model.backbone.W_P.weight: 240
module.model.backbone.W_P.bias: 20
module.model.backbone.W_P_coarse.weight: 1400
module.model.backbone.W_P_coarse.bias: 20
module.model.backbone.encoder.layers.0.self_attn.W_Q.weight: 400
module.model.backbone.encoder.layers.0.self_attn.W_Q.bias: 20
module.model.backbone.encoder.layers.0.self_attn.W_K.weight: 400
module.model.backbone.encoder.layers.0.self_attn.W_K.bias: 20
module.model.backbone.encoder.layers.0.self_attn.W_V.weight: 400
module.model.backbone.encoder.layers.0.self_attn.W_V.bias: 20
module.model.backbone.encoder.layers.0.self_attn.to_out.0.weight: 400
module.model.backbone.encoder.layers.0.self_attn.to_out.0.bias: 20
module.model.backbone.encoder.layers.0.norm_attn.1.weight: 20
module.model.backbone.encoder.layers.0.norm_attn.1.bias: 20
module.model.backbone.encoder.layers.0.ff.0.weight: 2560
module.model.backbone.encoder.layers.0.ff.0.bias: 128
module.model.backbone.encoder.layers.0.ff.3.weight: 2560
module.model.backbone.encoder.layers.0.ff.3.bias: 20
module.model.backbone.encoder.layers.0.norm_ffn.1.weight: 20
module.model.backbone.encoder.layers.0.norm_ffn.1.bias: 20
module.model.backbone.encoder.layers.1.self_attn.W_Q.weight: 400
module.model.backbone.encoder.layers.1.self_attn.W_Q.bias: 20
module.model.backbone.encoder.layers.1.self_attn.W_K.weight: 400
module.model.backbone.encoder.layers.1.self_attn.W_K.bias: 20
module.model.backbone.encoder.layers.1.self_attn.W_V.weight: 400
module.model.backbone.encoder.layers.1.self_attn.W_V.bias: 20
module.model.backbone.encoder.layers.1.self_attn.to_out.0.weight: 400
module.model.backbone.encoder.layers.1.self_attn.to_out.0.bias: 20
module.model.backbone.encoder.layers.1.norm_attn.1.weight: 20
module.model.backbone.encoder.layers.1.norm_attn.1.bias: 20
module.model.backbone.encoder.layers.1.ff.0.weight: 2560
module.model.backbone.encoder.layers.1.ff.0.bias: 128
module.model.backbone.encoder.layers.1.ff.3.weight: 2560
module.model.backbone.encoder.layers.1.ff.3.bias: 20
module.model.backbone.encoder.layers.1.norm_ffn.1.weight: 20
module.model.backbone.encoder.layers.1.norm_ffn.1.bias: 20
module.model.backbone.encoder.layers.2.self_attn.W_Q.weight: 400
module.model.backbone.encoder.layers.2.self_attn.W_Q.bias: 20
module.model.backbone.encoder.layers.2.self_attn.W_K.weight: 400
module.model.backbone.encoder.layers.2.self_attn.W_K.bias: 20
module.model.backbone.encoder.layers.2.self_attn.W_V.weight: 400
module.model.backbone.encoder.layers.2.self_attn.W_V.bias: 20
module.model.backbone.encoder.layers.2.self_attn.to_out.0.weight: 400
module.model.backbone.encoder.layers.2.self_attn.to_out.0.bias: 20
module.model.backbone.encoder.layers.2.norm_attn.1.weight: 20
module.model.backbone.encoder.layers.2.norm_attn.1.bias: 20
module.model.backbone.encoder.layers.2.ff.0.weight: 2560
module.model.backbone.encoder.layers.2.ff.0.bias: 128
module.model.backbone.encoder.layers.2.ff.3.weight: 2560
module.model.backbone.encoder.layers.2.ff.3.bias: 20
module.model.backbone.encoder.layers.2.norm_ffn.1.weight: 20
module.model.backbone.encoder.layers.2.norm_ffn.1.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.W_Q.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.W_K.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.W_V.bias: 20
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_intra.layers.0.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_intra.layers.0.norm_attn.1.weight: 20
module.model.backbone.encoder_intra.layers.0.norm_attn.1.bias: 20
module.model.backbone.encoder_intra.layers.0.ff.0.weight: 2560
module.model.backbone.encoder_intra.layers.0.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.0.ff.3.weight: 2560
module.model.backbone.encoder_intra.layers.0.ff.3.bias: 20
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.weight: 20
module.model.backbone.encoder_intra.layers.0.norm_ffn.1.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.W_Q.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.W_Q.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.W_K.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.W_K.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.W_V.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.W_V.bias: 20
module.model.backbone.encoder_intra.layers.1.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_intra.layers.1.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_intra.layers.1.norm_attn.1.weight: 20
module.model.backbone.encoder_intra.layers.1.norm_attn.1.bias: 20
module.model.backbone.encoder_intra.layers.1.ff.0.weight: 2560
module.model.backbone.encoder_intra.layers.1.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.1.ff.3.weight: 2560
module.model.backbone.encoder_intra.layers.1.ff.3.bias: 20
module.model.backbone.encoder_intra.layers.1.norm_ffn.1.weight: 20
module.model.backbone.encoder_intra.layers.1.norm_ffn.1.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.W_Q.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.W_Q.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.W_K.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.W_K.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.W_V.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.W_V.bias: 20
module.model.backbone.encoder_intra.layers.2.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_intra.layers.2.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_intra.layers.2.norm_attn.1.weight: 20
module.model.backbone.encoder_intra.layers.2.norm_attn.1.bias: 20
module.model.backbone.encoder_intra.layers.2.ff.0.weight: 2560
module.model.backbone.encoder_intra.layers.2.ff.0.bias: 128
module.model.backbone.encoder_intra.layers.2.ff.3.weight: 2560
module.model.backbone.encoder_intra.layers.2.ff.3.bias: 20
module.model.backbone.encoder_intra.layers.2.norm_ffn.1.weight: 20
module.model.backbone.encoder_intra.layers.2.norm_ffn.1.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_Q.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_K.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.W_V.bias: 20
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_coarse.layers.0.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.weight: 20
module.model.backbone.encoder_coarse.layers.0.norm_attn.1.bias: 20
module.model.backbone.encoder_coarse.layers.0.ff.0.weight: 2560
module.model.backbone.encoder_coarse.layers.0.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.0.ff.3.weight: 2560
module.model.backbone.encoder_coarse.layers.0.ff.3.bias: 20
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.weight: 20
module.model.backbone.encoder_coarse.layers.0.norm_ffn.1.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.W_Q.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_Q.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.W_K.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_K.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.W_V.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.W_V.bias: 20
module.model.backbone.encoder_coarse.layers.1.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_coarse.layers.1.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_coarse.layers.1.norm_attn.1.weight: 20
module.model.backbone.encoder_coarse.layers.1.norm_attn.1.bias: 20
module.model.backbone.encoder_coarse.layers.1.ff.0.weight: 2560
module.model.backbone.encoder_coarse.layers.1.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.1.ff.3.weight: 2560
module.model.backbone.encoder_coarse.layers.1.ff.3.bias: 20
module.model.backbone.encoder_coarse.layers.1.norm_ffn.1.weight: 20
module.model.backbone.encoder_coarse.layers.1.norm_ffn.1.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.W_Q.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_Q.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.W_K.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_K.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.W_V.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.W_V.bias: 20
module.model.backbone.encoder_coarse.layers.2.self_attn.to_out.0.weight: 400
module.model.backbone.encoder_coarse.layers.2.self_attn.to_out.0.bias: 20
module.model.backbone.encoder_coarse.layers.2.norm_attn.1.weight: 20
module.model.backbone.encoder_coarse.layers.2.norm_attn.1.bias: 20
module.model.backbone.encoder_coarse.layers.2.ff.0.weight: 2560
module.model.backbone.encoder_coarse.layers.2.ff.0.bias: 128
module.model.backbone.encoder_coarse.layers.2.ff.3.weight: 2560
module.model.backbone.encoder_coarse.layers.2.ff.3.bias: 20
module.model.backbone.encoder_coarse.layers.2.norm_ffn.1.weight: 20
module.model.backbone.encoder_coarse.layers.2.norm_ffn.1.bias: 20
module.model.head.linear.weight: 678720
module.model.head.linear.bias: 336
module.model.compress.weight: 960
module.model.compress.bias: 10
Total trainable parameters: 746638
train 8209
val 2545
test 2545
Epoch: 1 cost time: 10.856775760650635
[2024-12-07 20:50:44] [32mIntermediate result: 0.43407607  (Index 0)[0m
Epoch: 1, Steps: 64 | Train Loss: 0.7821802 Vali Loss: 0.4204935 Test Loss: 0.4340761
Validation loss decreased (inf --> 0.420493).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 9.972618818283081
[2024-12-07 20:50:57] [32mIntermediate result: 0.39129165  (Index 1)[0m
Epoch: 2, Steps: 64 | Train Loss: 0.7188183 Vali Loss: 0.3731799 Test Loss: 0.3912916
Validation loss decreased (0.420493 --> 0.373180).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 9.810566902160645
[2024-12-07 20:51:10] [32mIntermediate result: 0.38162392  (Index 2)[0m
Epoch: 3, Steps: 64 | Train Loss: 0.6879814 Vali Loss: 0.3684979 Test Loss: 0.3816239
Validation loss decreased (0.373180 --> 0.368498).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 10.151832342147827
[2024-12-07 20:51:24] [32mIntermediate result: 0.37798253  (Index 3)[0m
Epoch: 4, Steps: 64 | Train Loss: 0.6720811 Vali Loss: 0.3680144 Test Loss: 0.3779825
Validation loss decreased (0.368498 --> 0.368014).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 9.74570608139038
[2024-12-07 20:51:37] [32mIntermediate result: 0.3762926  (Index 4)[0m
Epoch: 5, Steps: 64 | Train Loss: 0.6606282 Vali Loss: 0.3616279 Test Loss: 0.3762926
Validation loss decreased (0.368014 --> 0.361628).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 9.937508821487427
[2024-12-07 20:51:51] [32mIntermediate result: 0.37496164  (Index 5)[0m
Epoch: 6, Steps: 64 | Train Loss: 0.6530743 Vali Loss: 0.3645004 Test Loss: 0.3749616
EarlyStopping counter: 1 out of 8
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 10.154243469238281
[2024-12-07 20:52:05] [32mIntermediate result: 0.37279043  (Index 6)[0m
Epoch: 7, Steps: 64 | Train Loss: 0.6449698 Vali Loss: 0.3644544 Test Loss: 0.3727904
EarlyStopping counter: 2 out of 8
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 10.215822458267212
[2024-12-07 20:52:19] [32mIntermediate result: 0.37101582  (Index 7)[0m
Epoch: 8, Steps: 64 | Train Loss: 0.6396061 Vali Loss: 0.3634858 Test Loss: 0.3710158
EarlyStopping counter: 3 out of 8
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 10.002359628677368
[2024-12-07 20:52:32] [32mIntermediate result: 0.37060046  (Index 8)[0m
Epoch: 9, Steps: 64 | Train Loss: 0.6335626 Vali Loss: 0.3640534 Test Loss: 0.3706005
EarlyStopping counter: 4 out of 8
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 10.420648097991943
[2024-12-07 20:52:46] [32mIntermediate result: 0.3689538  (Index 9)[0m
Epoch: 10, Steps: 64 | Train Loss: 0.6280673 Vali Loss: 0.3684187 Test Loss: 0.3689538
EarlyStopping counter: 5 out of 8
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 9.85653567314148
[2024-12-07 20:52:59] [32mIntermediate result: 0.36857793  (Index 10)[0m
Epoch: 11, Steps: 64 | Train Loss: 0.6245484 Vali Loss: 0.3604766 Test Loss: 0.3685779
Validation loss decreased (0.361628 --> 0.360477).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 10.108300685882568
[2024-12-07 20:53:13] [32mIntermediate result: 0.36948347  (Index 11)[0m
Epoch: 12, Steps: 64 | Train Loss: 0.6211457 Vali Loss: 0.3626522 Test Loss: 0.3694835
EarlyStopping counter: 1 out of 8
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 9.785420179367065
[2024-12-07 20:53:26] [32mIntermediate result: 0.3685013  (Index 12)[0m
Epoch: 13, Steps: 64 | Train Loss: 0.6166617 Vali Loss: 0.3612282 Test Loss: 0.3685013
EarlyStopping counter: 2 out of 8
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 10.04599118232727
[2024-12-07 20:53:40] [32mIntermediate result: 0.36779535  (Index 13)[0m
Epoch: 14, Steps: 64 | Train Loss: 0.6127204 Vali Loss: 0.3610234 Test Loss: 0.3677953
EarlyStopping counter: 3 out of 8
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 9.90995192527771
[2024-12-07 20:53:54] [32mIntermediate result: 0.36758953  (Index 14)[0m
Epoch: 15, Steps: 64 | Train Loss: 0.6102355 Vali Loss: 0.3613093 Test Loss: 0.3675895
EarlyStopping counter: 4 out of 8
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 9.872013568878174
[2024-12-07 20:54:07] [32mIntermediate result: 0.36749497  (Index 15)[0m
Epoch: 16, Steps: 64 | Train Loss: 0.6086445 Vali Loss: 0.3631407 Test Loss: 0.3674950
EarlyStopping counter: 5 out of 8
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 10.016033172607422
[2024-12-07 20:54:21] [32mIntermediate result: 0.3672627  (Index 16)[0m
Epoch: 17, Steps: 64 | Train Loss: 0.6041177 Vali Loss: 0.3612138 Test Loss: 0.3672627
EarlyStopping counter: 6 out of 8
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 9.925379514694214
[2024-12-07 20:54:34] [32mIntermediate result: 0.3668596  (Index 17)[0m
Epoch: 18, Steps: 64 | Train Loss: 0.6025704 Vali Loss: 0.3580208 Test Loss: 0.3668596
Validation loss decreased (0.360477 --> 0.358021).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 9.961887121200562
[2024-12-07 20:54:48] [32mIntermediate result: 0.36653066  (Index 18)[0m
Epoch: 19, Steps: 64 | Train Loss: 0.6013808 Vali Loss: 0.3621611 Test Loss: 0.3665307
EarlyStopping counter: 1 out of 8
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 9.961023807525635
[2024-12-07 20:55:01] [32mIntermediate result: 0.36694646  (Index 19)[0m
Epoch: 20, Steps: 64 | Train Loss: 0.5990361 Vali Loss: 0.3616524 Test Loss: 0.3669465
EarlyStopping counter: 2 out of 8
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 9.700232982635498
[2024-12-07 20:55:15] [32mIntermediate result: 0.3675157  (Index 20)[0m
Epoch: 21, Steps: 64 | Train Loss: 0.6002374 Vali Loss: 0.3612755 Test Loss: 0.3675157
EarlyStopping counter: 3 out of 8
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 10.135343313217163
[2024-12-07 20:55:29] [32mIntermediate result: 0.3667791  (Index 21)[0m
Epoch: 22, Steps: 64 | Train Loss: 0.5966939 Vali Loss: 0.3581986 Test Loss: 0.3667791
EarlyStopping counter: 4 out of 8
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 9.858400106430054
[2024-12-07 20:55:42] [32mIntermediate result: 0.3674964  (Index 22)[0m
Epoch: 23, Steps: 64 | Train Loss: 0.5950780 Vali Loss: 0.3599187 Test Loss: 0.3674964
EarlyStopping counter: 5 out of 8
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 10.092503547668457
[2024-12-07 20:55:56] [32mIntermediate result: 0.36710757  (Index 23)[0m
Epoch: 24, Steps: 64 | Train Loss: 0.5961027 Vali Loss: 0.3639463 Test Loss: 0.3671076
EarlyStopping counter: 6 out of 8
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 10.664859533309937
[2024-12-07 20:56:10] [32mIntermediate result: 0.3670964  (Index 24)[0m
Epoch: 25, Steps: 64 | Train Loss: 0.5957949 Vali Loss: 0.3630084 Test Loss: 0.3670964
EarlyStopping counter: 7 out of 8
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 9.988151550292969
[2024-12-07 20:56:24] [32mIntermediate result: 0.3672884  (Index 25)[0m
Epoch: 26, Steps: 64 | Train Loss: 0.5958064 Vali Loss: 0.3633110 Test Loss: 0.3672884
EarlyStopping counter: 8 out of 8
Early stopping
>>>>>>>testing : 24_2_2_96_336_MGSformer_TST_ETTh2_ftM_sl96_ll18_pl336_dm20_nh4_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.3668597638607025, mae:0.3983493745326996, rse:0.4838797450065613
[2024-12-07 20:56:27] [32mFinal result: 0.36685976[0m
